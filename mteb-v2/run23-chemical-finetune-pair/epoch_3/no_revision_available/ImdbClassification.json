{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.856216,
        "f1": 0.855827,
        "f1_weighted": 0.855827,
        "ap": 0.807253,
        "ap_weighted": 0.807253,
        "scores_per_experiment": [
          {
            "accuracy": 0.85504,
            "f1": 0.854045,
            "f1_weighted": 0.854045,
            "ap": 0.828504,
            "ap_weighted": 0.828504
          },
          {
            "accuracy": 0.87416,
            "f1": 0.874087,
            "f1_weighted": 0.874087,
            "ap": 0.834184,
            "ap_weighted": 0.834184
          },
          {
            "accuracy": 0.83132,
            "f1": 0.830511,
            "f1_weighted": 0.830511,
            "ap": 0.762108,
            "ap_weighted": 0.762108
          },
          {
            "accuracy": 0.89068,
            "f1": 0.890536,
            "f1_weighted": 0.890536,
            "ap": 0.859912,
            "ap_weighted": 0.859912
          },
          {
            "accuracy": 0.88796,
            "f1": 0.88796,
            "f1_weighted": 0.88796,
            "ap": 0.844601,
            "ap_weighted": 0.844601
          },
          {
            "accuracy": 0.84516,
            "f1": 0.845146,
            "f1_weighted": 0.845146,
            "ap": 0.793998,
            "ap_weighted": 0.793998
          },
          {
            "accuracy": 0.86012,
            "f1": 0.860118,
            "f1_weighted": 0.860118,
            "ap": 0.810719,
            "ap_weighted": 0.810719
          },
          {
            "accuracy": 0.82556,
            "f1": 0.823754,
            "f1_weighted": 0.823754,
            "ap": 0.750922,
            "ap_weighted": 0.750922
          },
          {
            "accuracy": 0.85048,
            "f1": 0.850472,
            "f1_weighted": 0.850472,
            "ap": 0.796256,
            "ap_weighted": 0.796256
          },
          {
            "accuracy": 0.84168,
            "f1": 0.841642,
            "f1_weighted": 0.841642,
            "ap": 0.791325,
            "ap_weighted": 0.791325
          }
        ],
        "main_score": 0.856216,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 86.89422821998596,
  "kg_co2_emissions": null
}