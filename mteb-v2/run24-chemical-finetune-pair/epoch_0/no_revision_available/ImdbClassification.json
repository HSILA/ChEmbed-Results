{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.862472,
        "f1": 0.862124,
        "f1_weighted": 0.862124,
        "ap": 0.814928,
        "ap_weighted": 0.814928,
        "scores_per_experiment": [
          {
            "accuracy": 0.86348,
            "f1": 0.862723,
            "f1_weighted": 0.862723,
            "ap": 0.83691,
            "ap_weighted": 0.83691
          },
          {
            "accuracy": 0.8662,
            "f1": 0.865912,
            "f1_weighted": 0.865912,
            "ap": 0.830907,
            "ap_weighted": 0.830907
          },
          {
            "accuracy": 0.85452,
            "f1": 0.854339,
            "f1_weighted": 0.854339,
            "ap": 0.794669,
            "ap_weighted": 0.794669
          },
          {
            "accuracy": 0.8998,
            "f1": 0.899604,
            "f1_weighted": 0.899604,
            "ap": 0.87524,
            "ap_weighted": 0.87524
          },
          {
            "accuracy": 0.89296,
            "f1": 0.892956,
            "f1_weighted": 0.892956,
            "ap": 0.848946,
            "ap_weighted": 0.848946
          },
          {
            "accuracy": 0.84588,
            "f1": 0.845807,
            "f1_weighted": 0.845807,
            "ap": 0.787592,
            "ap_weighted": 0.787592
          },
          {
            "accuracy": 0.86908,
            "f1": 0.868978,
            "f1_weighted": 0.868978,
            "ap": 0.813566,
            "ap_weighted": 0.813566
          },
          {
            "accuracy": 0.82,
            "f1": 0.818306,
            "f1_weighted": 0.818306,
            "ap": 0.745825,
            "ap_weighted": 0.745825
          },
          {
            "accuracy": 0.86256,
            "f1": 0.862535,
            "f1_weighted": 0.862535,
            "ap": 0.809289,
            "ap_weighted": 0.809289
          },
          {
            "accuracy": 0.85024,
            "f1": 0.850081,
            "f1_weighted": 0.850081,
            "ap": 0.806333,
            "ap_weighted": 0.806333
          }
        ],
        "main_score": 0.862472,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 108.6247889995575,
  "kg_co2_emissions": null
}