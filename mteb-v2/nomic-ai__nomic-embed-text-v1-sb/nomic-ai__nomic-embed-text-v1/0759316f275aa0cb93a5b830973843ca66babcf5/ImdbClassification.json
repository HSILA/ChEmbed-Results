{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.84174,
        "f1": 0.841236,
        "f1_weighted": 0.841236,
        "ap": 0.78815,
        "ap_weighted": 0.78815,
        "scores_per_experiment": [
          {
            "accuracy": 0.84484,
            "f1": 0.843277,
            "f1_weighted": 0.843277,
            "ap": 0.821019,
            "ap_weighted": 0.821019
          },
          {
            "accuracy": 0.85448,
            "f1": 0.854442,
            "f1_weighted": 0.854442,
            "ap": 0.798981,
            "ap_weighted": 0.798981
          },
          {
            "accuracy": 0.8382,
            "f1": 0.837479,
            "f1_weighted": 0.837479,
            "ap": 0.770035,
            "ap_weighted": 0.770035
          },
          {
            "accuracy": 0.88304,
            "f1": 0.882994,
            "f1_weighted": 0.882994,
            "ap": 0.844302,
            "ap_weighted": 0.844302
          },
          {
            "accuracy": 0.86032,
            "f1": 0.860316,
            "f1_weighted": 0.860316,
            "ap": 0.811376,
            "ap_weighted": 0.811376
          },
          {
            "accuracy": 0.82056,
            "f1": 0.820317,
            "f1_weighted": 0.820317,
            "ap": 0.771203,
            "ap_weighted": 0.771203
          },
          {
            "accuracy": 0.83876,
            "f1": 0.838717,
            "f1_weighted": 0.838717,
            "ap": 0.78052,
            "ap_weighted": 0.78052
          },
          {
            "accuracy": 0.80852,
            "f1": 0.806483,
            "f1_weighted": 0.806483,
            "ap": 0.733238,
            "ap_weighted": 0.733238
          },
          {
            "accuracy": 0.84416,
            "f1": 0.843842,
            "f1_weighted": 0.843842,
            "ap": 0.780722,
            "ap_weighted": 0.780722
          },
          {
            "accuracy": 0.82452,
            "f1": 0.824496,
            "f1_weighted": 0.824496,
            "ap": 0.770101,
            "ap_weighted": 0.770101
          }
        ],
        "main_score": 0.84174,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 196.00029683113098,
  "kg_co2_emissions": null
}