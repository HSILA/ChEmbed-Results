{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.653564,
        "f1": 0.502113,
        "f1_weighted": 0.729584,
        "ap": 0.119126,
        "ap_weighted": 0.119126,
        "scores_per_experiment": [
          {
            "accuracy": 0.668457,
            "f1": 0.51461,
            "f1_weighted": 0.744647,
            "ap": 0.124594,
            "ap_weighted": 0.124594
          },
          {
            "accuracy": 0.662109,
            "f1": 0.498402,
            "f1_weighted": 0.739625,
            "ap": 0.108257,
            "ap_weighted": 0.108257
          },
          {
            "accuracy": 0.715332,
            "f1": 0.539727,
            "f1_weighted": 0.77905,
            "ap": 0.129675,
            "ap_weighted": 0.129675
          },
          {
            "accuracy": 0.745117,
            "f1": 0.561148,
            "f1_weighted": 0.800336,
            "ap": 0.140503,
            "ap_weighted": 0.140503
          },
          {
            "accuracy": 0.504883,
            "f1": 0.418332,
            "f1_weighted": 0.60721,
            "ap": 0.10336,
            "ap_weighted": 0.10336
          },
          {
            "accuracy": 0.510254,
            "f1": 0.423362,
            "f1_weighted": 0.611791,
            "ap": 0.106472,
            "ap_weighted": 0.106472
          },
          {
            "accuracy": 0.749023,
            "f1": 0.544676,
            "f1_weighted": 0.801451,
            "ap": 0.118345,
            "ap_weighted": 0.118345
          },
          {
            "accuracy": 0.604004,
            "f1": 0.476409,
            "f1_weighted": 0.69399,
            "ap": 0.114007,
            "ap_weighted": 0.114007
          },
          {
            "accuracy": 0.65332,
            "f1": 0.499251,
            "f1_weighted": 0.733068,
            "ap": 0.113744,
            "ap_weighted": 0.113744
          },
          {
            "accuracy": 0.723145,
            "f1": 0.545217,
            "f1_weighted": 0.784676,
            "ap": 0.132304,
            "ap_weighted": 0.132304
          }
        ],
        "main_score": 0.653564,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.703431844711304,
  "kg_co2_emissions": null
}