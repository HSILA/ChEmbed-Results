{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.784328,
        "f1": 0.727989,
        "f1_weighted": 0.803004,
        "ap": 0.430598,
        "ap_weighted": 0.430598,
        "scores_per_experiment": [
          {
            "accuracy": 0.756716,
            "f1": 0.6854,
            "f1_weighted": 0.776614,
            "ap": 0.361817,
            "ap_weighted": 0.361817
          },
          {
            "accuracy": 0.834328,
            "f1": 0.776411,
            "f1_weighted": 0.845708,
            "ap": 0.49089,
            "ap_weighted": 0.49089
          },
          {
            "accuracy": 0.735821,
            "f1": 0.685947,
            "f1_weighted": 0.762159,
            "ap": 0.385223,
            "ap_weighted": 0.385223
          },
          {
            "accuracy": 0.773134,
            "f1": 0.714321,
            "f1_weighted": 0.793255,
            "ap": 0.407723,
            "ap_weighted": 0.407723
          },
          {
            "accuracy": 0.78209,
            "f1": 0.729243,
            "f1_weighted": 0.802085,
            "ap": 0.433629,
            "ap_weighted": 0.433629
          },
          {
            "accuracy": 0.797015,
            "f1": 0.739883,
            "f1_weighted": 0.814118,
            "ap": 0.441861,
            "ap_weighted": 0.441861
          },
          {
            "accuracy": 0.858209,
            "f1": 0.800207,
            "f1_weighted": 0.865761,
            "ap": 0.526815,
            "ap_weighted": 0.526815
          },
          {
            "accuracy": 0.81194,
            "f1": 0.751706,
            "f1_weighted": 0.826178,
            "ap": 0.453988,
            "ap_weighted": 0.453988
          },
          {
            "accuracy": 0.726866,
            "f1": 0.678879,
            "f1_weighted": 0.754472,
            "ap": 0.379681,
            "ap_weighted": 0.379681
          },
          {
            "accuracy": 0.767164,
            "f1": 0.717895,
            "f1_weighted": 0.789687,
            "ap": 0.424356,
            "ap_weighted": 0.424356
          }
        ],
        "main_score": 0.784328,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.650252342224121,
  "kg_co2_emissions": null
}