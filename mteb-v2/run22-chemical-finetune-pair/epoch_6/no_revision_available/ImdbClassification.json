{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.864788,
        "f1": 0.864483,
        "f1_weighted": 0.864483,
        "ap": 0.817188,
        "ap_weighted": 0.817188,
        "scores_per_experiment": [
          {
            "accuracy": 0.85248,
            "f1": 0.851479,
            "f1_weighted": 0.851479,
            "ap": 0.824883,
            "ap_weighted": 0.824883
          },
          {
            "accuracy": 0.86984,
            "f1": 0.869694,
            "f1_weighted": 0.869694,
            "ap": 0.831505,
            "ap_weighted": 0.831505
          },
          {
            "accuracy": 0.8634,
            "f1": 0.863307,
            "f1_weighted": 0.863307,
            "ap": 0.807222,
            "ap_weighted": 0.807222
          },
          {
            "accuracy": 0.90276,
            "f1": 0.902632,
            "f1_weighted": 0.902632,
            "ap": 0.876257,
            "ap_weighted": 0.876257
          },
          {
            "accuracy": 0.89856,
            "f1": 0.898552,
            "f1_weighted": 0.898552,
            "ap": 0.855407,
            "ap_weighted": 0.855407
          },
          {
            "accuracy": 0.8568,
            "f1": 0.85665,
            "f1_weighted": 0.85665,
            "ap": 0.797959,
            "ap_weighted": 0.797959
          },
          {
            "accuracy": 0.86992,
            "f1": 0.869895,
            "f1_weighted": 0.869895,
            "ap": 0.818094,
            "ap_weighted": 0.818094
          },
          {
            "accuracy": 0.83044,
            "f1": 0.82914,
            "f1_weighted": 0.82914,
            "ap": 0.758189,
            "ap_weighted": 0.758189
          },
          {
            "accuracy": 0.86136,
            "f1": 0.861309,
            "f1_weighted": 0.861309,
            "ap": 0.806452,
            "ap_weighted": 0.806452
          },
          {
            "accuracy": 0.84232,
            "f1": 0.842175,
            "f1_weighted": 0.842175,
            "ap": 0.795908,
            "ap_weighted": 0.795908
          }
        ],
        "main_score": 0.864788,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 88.28931951522827,
  "kg_co2_emissions": null
}