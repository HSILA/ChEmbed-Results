{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.866488,
        "f1": 0.866201,
        "f1_weighted": 0.866201,
        "ap": 0.819562,
        "ap_weighted": 0.819562,
        "scores_per_experiment": [
          {
            "accuracy": 0.85184,
            "f1": 0.85073,
            "f1_weighted": 0.85073,
            "ap": 0.825513,
            "ap_weighted": 0.825513
          },
          {
            "accuracy": 0.87344,
            "f1": 0.873325,
            "f1_weighted": 0.873325,
            "ap": 0.835104,
            "ap_weighted": 0.835104
          },
          {
            "accuracy": 0.86932,
            "f1": 0.869294,
            "f1_weighted": 0.869294,
            "ap": 0.817332,
            "ap_weighted": 0.817332
          },
          {
            "accuracy": 0.90488,
            "f1": 0.904771,
            "f1_weighted": 0.904771,
            "ap": 0.878268,
            "ap_weighted": 0.878268
          },
          {
            "accuracy": 0.89988,
            "f1": 0.899871,
            "f1_weighted": 0.899871,
            "ap": 0.856795,
            "ap_weighted": 0.856795
          },
          {
            "accuracy": 0.85504,
            "f1": 0.854867,
            "f1_weighted": 0.854867,
            "ap": 0.795424,
            "ap_weighted": 0.795424
          },
          {
            "accuracy": 0.86976,
            "f1": 0.869759,
            "f1_weighted": 0.869759,
            "ap": 0.820733,
            "ap_weighted": 0.820733
          },
          {
            "accuracy": 0.83404,
            "f1": 0.832841,
            "f1_weighted": 0.832841,
            "ap": 0.762442,
            "ap_weighted": 0.762442
          },
          {
            "accuracy": 0.86404,
            "f1": 0.86399,
            "f1_weighted": 0.86399,
            "ap": 0.809654,
            "ap_weighted": 0.809654
          },
          {
            "accuracy": 0.84264,
            "f1": 0.842558,
            "f1_weighted": 0.842558,
            "ap": 0.794352,
            "ap_weighted": 0.794352
          }
        ],
        "main_score": 0.866488,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 114.18667721748352,
  "kg_co2_emissions": null
}