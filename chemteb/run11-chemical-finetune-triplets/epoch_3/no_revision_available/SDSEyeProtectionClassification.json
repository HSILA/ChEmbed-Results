{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.67305,
        "f1": 0.4062,
        "f1_weighted": 0.798247,
        "ap": 0.998531,
        "ap_weighted": 0.998531,
        "scores_per_experiment": [
          {
            "accuracy": 0.7035,
            "f1": 0.417828,
            "f1_weighted": 0.8236,
            "ap": 0.998258,
            "ap_weighted": 0.998258
          },
          {
            "accuracy": 0.5225,
            "f1": 0.345998,
            "f1_weighted": 0.684053,
            "ap": 0.997805,
            "ap_weighted": 0.997805
          },
          {
            "accuracy": 0.6045,
            "f1": 0.381451,
            "f1_weighted": 0.751033,
            "ap": 0.998509,
            "ap_weighted": 0.998509
          },
          {
            "accuracy": 0.738,
            "f1": 0.431971,
            "f1_weighted": 0.84682,
            "ap": 0.998844,
            "ap_weighted": 0.998844
          },
          {
            "accuracy": 0.667,
            "f1": 0.407216,
            "f1_weighted": 0.797677,
            "ap": 0.999165,
            "ap_weighted": 0.999165
          },
          {
            "accuracy": 0.7925,
            "f1": 0.449149,
            "f1_weighted": 0.881871,
            "ap": 0.998481,
            "ap_weighted": 0.998481
          },
          {
            "accuracy": 0.6985,
            "f1": 0.416014,
            "f1_weighted": 0.820146,
            "ap": 0.998246,
            "ap_weighted": 0.998246
          },
          {
            "accuracy": 0.82,
            "f1": 0.46131,
            "f1_weighted": 0.898683,
            "ap": 0.999049,
            "ap_weighted": 0.999049
          },
          {
            "accuracy": 0.5295,
            "f1": 0.350003,
            "f1_weighted": 0.689869,
            "ap": 0.998321,
            "ap_weighted": 0.998321
          },
          {
            "accuracy": 0.6545,
            "f1": 0.401057,
            "f1_weighted": 0.788721,
            "ap": 0.998634,
            "ap_weighted": 0.998634
          }
        ],
        "main_score": 0.67305,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.91825008392334,
  "kg_co2_emissions": null
}