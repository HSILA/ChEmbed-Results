{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.63156,
        "f1": 0.627419,
        "f1_weighted": 0.6285,
        "ap": 0.556598,
        "ap_weighted": 0.556598,
        "scores_per_experiment": [
          {
            "accuracy": 0.636418,
            "f1": 0.633905,
            "f1_weighted": 0.632158,
            "ap": 0.560332,
            "ap_weighted": 0.560332
          },
          {
            "accuracy": 0.625364,
            "f1": 0.624184,
            "f1_weighted": 0.625397,
            "ap": 0.550305,
            "ap_weighted": 0.550305
          },
          {
            "accuracy": 0.704284,
            "f1": 0.703565,
            "f1_weighted": 0.704406,
            "ap": 0.618403,
            "ap_weighted": 0.618403
          },
          {
            "accuracy": 0.608398,
            "f1": 0.584586,
            "f1_weighted": 0.590313,
            "ap": 0.536335,
            "ap_weighted": 0.536335
          },
          {
            "accuracy": 0.568809,
            "f1": 0.568585,
            "f1_weighted": 0.569151,
            "ap": 0.5108,
            "ap_weighted": 0.5108
          },
          {
            "accuracy": 0.663153,
            "f1": 0.662816,
            "f1_weighted": 0.662202,
            "ap": 0.580811,
            "ap_weighted": 0.580811
          },
          {
            "accuracy": 0.653985,
            "f1": 0.653918,
            "f1_weighted": 0.653641,
            "ap": 0.573357,
            "ap_weighted": 0.573357
          },
          {
            "accuracy": 0.638903,
            "f1": 0.636035,
            "f1_weighted": 0.637895,
            "ap": 0.561054,
            "ap_weighted": 0.561054
          },
          {
            "accuracy": 0.607969,
            "f1": 0.607883,
            "f1_weighted": 0.607548,
            "ap": 0.538361,
            "ap_weighted": 0.538361
          },
          {
            "accuracy": 0.608312,
            "f1": 0.598712,
            "f1_weighted": 0.602286,
            "ap": 0.536224,
            "ap_weighted": 0.536224
          }
        ],
        "main_score": 0.63156,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.843332052230835,
  "kg_co2_emissions": null
}