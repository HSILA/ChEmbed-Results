{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.654173,
        "f1": 0.651322,
        "f1_weighted": 0.652152,
        "ap": 0.574588,
        "ap_weighted": 0.574588,
        "scores_per_experiment": [
          {
            "accuracy": 0.666752,
            "f1": 0.666586,
            "f1_weighted": 0.666156,
            "ap": 0.583778,
            "ap_weighted": 0.583778
          },
          {
            "accuracy": 0.637875,
            "f1": 0.637858,
            "f1_weighted": 0.637715,
            "ap": 0.560565,
            "ap_weighted": 0.560565
          },
          {
            "accuracy": 0.723222,
            "f1": 0.722978,
            "f1_weighted": 0.723451,
            "ap": 0.635735,
            "ap_weighted": 0.635735
          },
          {
            "accuracy": 0.654841,
            "f1": 0.643381,
            "f1_weighted": 0.647063,
            "ap": 0.576731,
            "ap_weighted": 0.576731
          },
          {
            "accuracy": 0.625021,
            "f1": 0.623483,
            "f1_weighted": 0.624869,
            "ap": 0.549974,
            "ap_weighted": 0.549974
          },
          {
            "accuracy": 0.650985,
            "f1": 0.648583,
            "f1_weighted": 0.646909,
            "ap": 0.571408,
            "ap_weighted": 0.571408
          },
          {
            "accuracy": 0.670437,
            "f1": 0.67015,
            "f1_weighted": 0.669591,
            "ap": 0.586809,
            "ap_weighted": 0.586809
          },
          {
            "accuracy": 0.643188,
            "f1": 0.641062,
            "f1_weighted": 0.642653,
            "ap": 0.564566,
            "ap_weighted": 0.564566
          },
          {
            "accuracy": 0.631191,
            "f1": 0.631027,
            "f1_weighted": 0.631475,
            "ap": 0.555133,
            "ap_weighted": 0.555133
          },
          {
            "accuracy": 0.638218,
            "f1": 0.628109,
            "f1_weighted": 0.63164,
            "ap": 0.561182,
            "ap_weighted": 0.561182
          }
        ],
        "main_score": 0.654173,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.35714054107666,
  "kg_co2_emissions": null
}