{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.69195,
        "f1": 0.413066,
        "f1_weighted": 0.806017,
        "ap": 0.997267,
        "ap_weighted": 0.997267,
        "scores_per_experiment": [
          {
            "accuracy": 0.863,
            "f1": 0.466835,
            "f1_weighted": 0.922746,
            "ap": 0.995964,
            "ap_weighted": 0.995964
          },
          {
            "accuracy": 0.7815,
            "f1": 0.447526,
            "f1_weighted": 0.873638,
            "ap": 0.997128,
            "ap_weighted": 0.997128
          },
          {
            "accuracy": 0.625,
            "f1": 0.392062,
            "f1_weighted": 0.765365,
            "ap": 0.997496,
            "ap_weighted": 0.997496
          },
          {
            "accuracy": 0.7495,
            "f1": 0.437988,
            "f1_weighted": 0.853059,
            "ap": 0.997497,
            "ap_weighted": 0.997497
          },
          {
            "accuracy": 0.8395,
            "f1": 0.468437,
            "f1_weighted": 0.909005,
            "ap": 0.99736,
            "ap_weighted": 0.99736
          },
          {
            "accuracy": 0.6885,
            "f1": 0.413878,
            "f1_weighted": 0.811869,
            "ap": 0.996755,
            "ap_weighted": 0.996755
          },
          {
            "accuracy": 0.645,
            "f1": 0.401305,
            "f1_weighted": 0.780217,
            "ap": 0.998075,
            "ap_weighted": 0.998075
          },
          {
            "accuracy": 0.428,
            "f1": 0.304065,
            "f1_weighted": 0.5954,
            "ap": 0.996705,
            "ap_weighted": 0.996705
          },
          {
            "accuracy": 0.506,
            "f1": 0.34221,
            "f1_weighted": 0.667821,
            "ap": 0.997517,
            "ap_weighted": 0.997517
          },
          {
            "accuracy": 0.7935,
            "f1": 0.456355,
            "f1_weighted": 0.881051,
            "ap": 0.998172,
            "ap_weighted": 0.998172
          }
        ],
        "main_score": 0.69195,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.030957460403442,
  "kg_co2_emissions": null
}