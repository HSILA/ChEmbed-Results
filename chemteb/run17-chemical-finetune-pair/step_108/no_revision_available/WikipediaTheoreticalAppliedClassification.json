{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.661842,
        "f1": 0.659143,
        "f1_weighted": 0.659956,
        "ap": 0.580966,
        "ap_weighted": 0.580966,
        "scores_per_experiment": [
          {
            "accuracy": 0.700343,
            "f1": 0.70032,
            "f1_weighted": 0.700171,
            "ap": 0.612938,
            "ap_weighted": 0.612938
          },
          {
            "accuracy": 0.646444,
            "f1": 0.645735,
            "f1_weighted": 0.644823,
            "ap": 0.56755,
            "ap_weighted": 0.56755
          },
          {
            "accuracy": 0.720394,
            "f1": 0.720356,
            "f1_weighted": 0.720545,
            "ap": 0.632183,
            "ap_weighted": 0.632183
          },
          {
            "accuracy": 0.673693,
            "f1": 0.665813,
            "f1_weighted": 0.668768,
            "ap": 0.593664,
            "ap_weighted": 0.593664
          },
          {
            "accuracy": 0.627763,
            "f1": 0.626744,
            "f1_weighted": 0.627867,
            "ap": 0.552206,
            "ap_weighted": 0.552206
          },
          {
            "accuracy": 0.67395,
            "f1": 0.672856,
            "f1_weighted": 0.671766,
            "ap": 0.589636,
            "ap_weighted": 0.589636
          },
          {
            "accuracy": 0.66461,
            "f1": 0.664411,
            "f1_weighted": 0.663941,
            "ap": 0.582008,
            "ap_weighted": 0.582008
          },
          {
            "accuracy": 0.662468,
            "f1": 0.660352,
            "f1_weighted": 0.661896,
            "ap": 0.581032,
            "ap_weighted": 0.581032
          },
          {
            "accuracy": 0.639417,
            "f1": 0.639026,
            "f1_weighted": 0.63971,
            "ap": 0.561524,
            "ap_weighted": 0.561524
          },
          {
            "accuracy": 0.60934,
            "f1": 0.595812,
            "f1_weighted": 0.60007,
            "ap": 0.536923,
            "ap_weighted": 0.536923
          }
        ],
        "main_score": 0.661842,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.527893543243408,
  "kg_co2_emissions": null
}