{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.661508,
        "f1": 0.658789,
        "f1_weighted": 0.659608,
        "ap": 0.580666,
        "ap_weighted": 0.580666,
        "scores_per_experiment": [
          {
            "accuracy": 0.699829,
            "f1": 0.699795,
            "f1_weighted": 0.699613,
            "ap": 0.612432,
            "ap_weighted": 0.612432
          },
          {
            "accuracy": 0.646272,
            "f1": 0.645585,
            "f1_weighted": 0.644686,
            "ap": 0.567411,
            "ap_weighted": 0.567411
          },
          {
            "accuracy": 0.718338,
            "f1": 0.71829,
            "f1_weighted": 0.7185,
            "ap": 0.630274,
            "ap_weighted": 0.630274
          },
          {
            "accuracy": 0.672579,
            "f1": 0.664445,
            "f1_weighted": 0.667453,
            "ap": 0.592686,
            "ap_weighted": 0.592686
          },
          {
            "accuracy": 0.627763,
            "f1": 0.626777,
            "f1_weighted": 0.627882,
            "ap": 0.552212,
            "ap_weighted": 0.552212
          },
          {
            "accuracy": 0.675664,
            "f1": 0.674607,
            "f1_weighted": 0.67354,
            "ap": 0.591052,
            "ap_weighted": 0.591052
          },
          {
            "accuracy": 0.665638,
            "f1": 0.665454,
            "f1_weighted": 0.665002,
            "ap": 0.582856,
            "ap_weighted": 0.582856
          },
          {
            "accuracy": 0.662896,
            "f1": 0.660816,
            "f1_weighted": 0.662345,
            "ap": 0.581398,
            "ap_weighted": 0.581398
          },
          {
            "accuracy": 0.636675,
            "f1": 0.63631,
            "f1_weighted": 0.636974,
            "ap": 0.559351,
            "ap_weighted": 0.559351
          },
          {
            "accuracy": 0.609426,
            "f1": 0.595809,
            "f1_weighted": 0.600081,
            "ap": 0.536991,
            "ap_weighted": 0.536991
          }
        ],
        "main_score": 0.661508,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.38151526451111,
  "kg_co2_emissions": null
}