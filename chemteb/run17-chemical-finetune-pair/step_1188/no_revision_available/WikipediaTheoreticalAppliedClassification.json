{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.661825,
        "f1": 0.65909,
        "f1_weighted": 0.659912,
        "ap": 0.58096,
        "ap_weighted": 0.58096,
        "scores_per_experiment": [
          {
            "accuracy": 0.699914,
            "f1": 0.699887,
            "f1_weighted": 0.699721,
            "ap": 0.61253,
            "ap_weighted": 0.61253
          },
          {
            "accuracy": 0.646187,
            "f1": 0.645534,
            "f1_weighted": 0.644657,
            "ap": 0.567335,
            "ap_weighted": 0.567335
          },
          {
            "accuracy": 0.719537,
            "f1": 0.719476,
            "f1_weighted": 0.719715,
            "ap": 0.631496,
            "ap_weighted": 0.631496
          },
          {
            "accuracy": 0.673265,
            "f1": 0.66522,
            "f1_weighted": 0.668209,
            "ap": 0.593319,
            "ap_weighted": 0.593319
          },
          {
            "accuracy": 0.628363,
            "f1": 0.627348,
            "f1_weighted": 0.628468,
            "ap": 0.552675,
            "ap_weighted": 0.552675
          },
          {
            "accuracy": 0.675321,
            "f1": 0.674218,
            "f1_weighted": 0.673127,
            "ap": 0.590766,
            "ap_weighted": 0.590766
          },
          {
            "accuracy": 0.666581,
            "f1": 0.666385,
            "f1_weighted": 0.665919,
            "ap": 0.583632,
            "ap_weighted": 0.583632
          },
          {
            "accuracy": 0.663239,
            "f1": 0.661151,
            "f1_weighted": 0.662683,
            "ap": 0.581702,
            "ap_weighted": 0.581702
          },
          {
            "accuracy": 0.636418,
            "f1": 0.636085,
            "f1_weighted": 0.636719,
            "ap": 0.559156,
            "ap_weighted": 0.559156
          },
          {
            "accuracy": 0.609426,
            "f1": 0.595597,
            "f1_weighted": 0.599904,
            "ap": 0.536989,
            "ap_weighted": 0.536989
          }
        ],
        "main_score": 0.661825,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.51576542854309,
  "kg_co2_emissions": null
}