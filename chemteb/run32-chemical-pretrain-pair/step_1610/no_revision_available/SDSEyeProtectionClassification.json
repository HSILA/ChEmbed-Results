{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.6803,
        "f1": 0.408206,
        "f1_weighted": 0.805144,
        "ap": 0.998151,
        "ap_weighted": 0.998151,
        "scores_per_experiment": [
          {
            "accuracy": 0.7405,
            "f1": 0.429191,
            "f1_weighted": 0.848626,
            "ap": 0.997853,
            "ap_weighted": 0.997853
          },
          {
            "accuracy": 0.701,
            "f1": 0.416922,
            "f1_weighted": 0.821876,
            "ap": 0.998252,
            "ap_weighted": 0.998252
          },
          {
            "accuracy": 0.6495,
            "f1": 0.397805,
            "f1_weighted": 0.785178,
            "ap": 0.998123,
            "ap_weighted": 0.998123
          },
          {
            "accuracy": 0.6495,
            "f1": 0.397805,
            "f1_weighted": 0.785178,
            "ap": 0.998123,
            "ap_weighted": 0.998123
          },
          {
            "accuracy": 0.757,
            "f1": 0.434851,
            "f1_weighted": 0.859405,
            "ap": 0.997894,
            "ap_weighted": 0.997894
          },
          {
            "accuracy": 0.698,
            "f1": 0.414256,
            "f1_weighted": 0.819896,
            "ap": 0.997746,
            "ap_weighted": 0.997746
          },
          {
            "accuracy": 0.697,
            "f1": 0.417029,
            "f1_weighted": 0.819008,
            "ap": 0.998741,
            "ap_weighted": 0.998741
          },
          {
            "accuracy": 0.746,
            "f1": 0.432974,
            "f1_weighted": 0.852168,
            "ap": 0.998365,
            "ap_weighted": 0.998365
          },
          {
            "accuracy": 0.6665,
            "f1": 0.407024,
            "f1_weighted": 0.797316,
            "ap": 0.999164,
            "ap_weighted": 0.999164
          },
          {
            "accuracy": 0.498,
            "f1": 0.334203,
            "f1_weighted": 0.662787,
            "ap": 0.997246,
            "ap_weighted": 0.997246
          }
        ],
        "main_score": 0.6803,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.79498553276062,
  "kg_co2_emissions": null
}