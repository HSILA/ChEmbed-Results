{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.5735,
        "f1": 0.359503,
        "f1_weighted": 0.703675,
        "ap": 0.996841,
        "ap_weighted": 0.996841,
        "scores_per_experiment": [
          {
            "accuracy": 0.7335,
            "f1": 0.430348,
            "f1_weighted": 0.842585,
            "ap": 0.996935,
            "ap_weighted": 0.996935
          },
          {
            "accuracy": 0.795,
            "f1": 0.452339,
            "f1_weighted": 0.882073,
            "ap": 0.997182,
            "ap_weighted": 0.997182
          },
          {
            "accuracy": 0.314,
            "f1": 0.242617,
            "f1_weighted": 0.473274,
            "ap": 0.996746,
            "ap_weighted": 0.996746
          },
          {
            "accuracy": 0.6265,
            "f1": 0.391434,
            "f1_weighted": 0.766632,
            "ap": 0.997004,
            "ap_weighted": 0.997004
          },
          {
            "accuracy": 0.7735,
            "f1": 0.440447,
            "f1_weighted": 0.868689,
            "ap": 0.996102,
            "ap_weighted": 0.996102
          },
          {
            "accuracy": 0.707,
            "f1": 0.420709,
            "f1_weighted": 0.824693,
            "ap": 0.996829,
            "ap_weighted": 0.996829
          },
          {
            "accuracy": 0.5705,
            "f1": 0.368577,
            "f1_weighted": 0.72279,
            "ap": 0.996779,
            "ap_weighted": 0.996779
          },
          {
            "accuracy": 0.2145,
            "f1": 0.179158,
            "f1_weighted": 0.34812,
            "ap": 0.996347,
            "ap_weighted": 0.996347
          },
          {
            "accuracy": 0.3795,
            "f1": 0.280152,
            "f1_weighted": 0.545436,
            "ap": 0.997508,
            "ap_weighted": 0.997508
          },
          {
            "accuracy": 0.621,
            "f1": 0.389246,
            "f1_weighted": 0.76246,
            "ap": 0.996982,
            "ap_weighted": 0.996982
          }
        ],
        "main_score": 0.5735,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.80112338066101,
  "kg_co2_emissions": null
}