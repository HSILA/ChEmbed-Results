{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.635458,
        "f1": 0.632543,
        "f1_weighted": 0.633622,
        "ap": 0.55943,
        "ap_weighted": 0.55943,
        "scores_per_experiment": [
          {
            "accuracy": 0.642245,
            "f1": 0.640905,
            "f1_weighted": 0.639641,
            "ap": 0.564466,
            "ap_weighted": 0.564466
          },
          {
            "accuracy": 0.608055,
            "f1": 0.606931,
            "f1_weighted": 0.608141,
            "ap": 0.537217,
            "ap_weighted": 0.537217
          },
          {
            "accuracy": 0.686375,
            "f1": 0.683267,
            "f1_weighted": 0.685074,
            "ap": 0.603416,
            "ap_weighted": 0.603416
          },
          {
            "accuracy": 0.633162,
            "f1": 0.625026,
            "f1_weighted": 0.628207,
            "ap": 0.556575,
            "ap_weighted": 0.556575
          },
          {
            "accuracy": 0.609683,
            "f1": 0.608855,
            "f1_weighted": 0.607818,
            "ap": 0.540197,
            "ap_weighted": 0.540197
          },
          {
            "accuracy": 0.626307,
            "f1": 0.625728,
            "f1_weighted": 0.62488,
            "ap": 0.552161,
            "ap_weighted": 0.552161
          },
          {
            "accuracy": 0.647301,
            "f1": 0.644607,
            "f1_weighted": 0.646389,
            "ap": 0.568068,
            "ap_weighted": 0.568068
          },
          {
            "accuracy": 0.622108,
            "f1": 0.62153,
            "f1_weighted": 0.622382,
            "ap": 0.547963,
            "ap_weighted": 0.547963
          },
          {
            "accuracy": 0.624422,
            "f1": 0.618257,
            "f1_weighted": 0.62105,
            "ap": 0.549217,
            "ap_weighted": 0.549217
          },
          {
            "accuracy": 0.654927,
            "f1": 0.650324,
            "f1_weighted": 0.652634,
            "ap": 0.575019,
            "ap_weighted": 0.575019
          }
        ],
        "main_score": 0.635458,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.94446563720703,
  "kg_co2_emissions": null
}