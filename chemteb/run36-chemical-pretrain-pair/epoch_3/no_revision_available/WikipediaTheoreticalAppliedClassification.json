{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.620308,
        "f1": 0.616776,
        "f1_weighted": 0.617792,
        "ap": 0.547286,
        "ap_weighted": 0.547286,
        "scores_per_experiment": [
          {
            "accuracy": 0.642074,
            "f1": 0.641444,
            "f1_weighted": 0.640579,
            "ap": 0.564136,
            "ap_weighted": 0.564136
          },
          {
            "accuracy": 0.610197,
            "f1": 0.61013,
            "f1_weighted": 0.610424,
            "ap": 0.539457,
            "ap_weighted": 0.539457
          },
          {
            "accuracy": 0.662554,
            "f1": 0.661567,
            "f1_weighted": 0.662619,
            "ap": 0.580761,
            "ap_weighted": 0.580761
          },
          {
            "accuracy": 0.620908,
            "f1": 0.61454,
            "f1_weighted": 0.617393,
            "ap": 0.546371,
            "ap_weighted": 0.546371
          },
          {
            "accuracy": 0.620823,
            "f1": 0.618091,
            "f1_weighted": 0.619951,
            "ap": 0.546534,
            "ap_weighted": 0.546534
          },
          {
            "accuracy": 0.620566,
            "f1": 0.619485,
            "f1_weighted": 0.618317,
            "ap": 0.548163,
            "ap_weighted": 0.548163
          },
          {
            "accuracy": 0.628363,
            "f1": 0.628363,
            "f1_weighted": 0.628335,
            "ap": 0.553196,
            "ap_weighted": 0.553196
          },
          {
            "accuracy": 0.64533,
            "f1": 0.644016,
            "f1_weighted": 0.645261,
            "ap": 0.566292,
            "ap_weighted": 0.566292
          },
          {
            "accuracy": 0.577806,
            "f1": 0.577388,
            "f1_weighted": 0.576623,
            "ap": 0.518101,
            "ap_weighted": 0.518101
          },
          {
            "accuracy": 0.574464,
            "f1": 0.552739,
            "f1_weighted": 0.558416,
            "ap": 0.509846,
            "ap_weighted": 0.509846
          }
        ],
        "main_score": 0.620308,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.34487009048462,
  "kg_co2_emissions": null
}