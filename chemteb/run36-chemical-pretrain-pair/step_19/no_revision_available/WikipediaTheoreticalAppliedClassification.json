{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.624516,
        "f1": 0.621093,
        "f1_weighted": 0.622028,
        "ap": 0.550447,
        "ap_weighted": 0.550447,
        "scores_per_experiment": [
          {
            "accuracy": 0.651757,
            "f1": 0.651367,
            "f1_weighted": 0.650696,
            "ap": 0.571649,
            "ap_weighted": 0.571649
          },
          {
            "accuracy": 0.613967,
            "f1": 0.613962,
            "f1_weighted": 0.614044,
            "ap": 0.542373,
            "ap_weighted": 0.542373
          },
          {
            "accuracy": 0.667095,
            "f1": 0.666721,
            "f1_weighted": 0.667364,
            "ap": 0.584432,
            "ap_weighted": 0.584432
          },
          {
            "accuracy": 0.622022,
            "f1": 0.617086,
            "f1_weighted": 0.61959,
            "ap": 0.547312,
            "ap_weighted": 0.547312
          },
          {
            "accuracy": 0.627078,
            "f1": 0.624308,
            "f1_weighted": 0.626166,
            "ap": 0.55146,
            "ap_weighted": 0.55146
          },
          {
            "accuracy": 0.622279,
            "f1": 0.620915,
            "f1_weighted": 0.619606,
            "ap": 0.549528,
            "ap_weighted": 0.549528
          },
          {
            "accuracy": 0.632305,
            "f1": 0.632305,
            "f1_weighted": 0.632328,
            "ap": 0.556184,
            "ap_weighted": 0.556184
          },
          {
            "accuracy": 0.645673,
            "f1": 0.644518,
            "f1_weighted": 0.645685,
            "ap": 0.566567,
            "ap_weighted": 0.566567
          },
          {
            "accuracy": 0.588946,
            "f1": 0.588517,
            "f1_weighted": 0.587751,
            "ap": 0.525525,
            "ap_weighted": 0.525525
          },
          {
            "accuracy": 0.574036,
            "f1": 0.551226,
            "f1_weighted": 0.557052,
            "ap": 0.509443,
            "ap_weighted": 0.509443
          }
        ],
        "main_score": 0.624516,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.471936464309692,
  "kg_co2_emissions": null
}