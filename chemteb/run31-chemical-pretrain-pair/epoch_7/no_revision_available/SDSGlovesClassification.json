{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.57165,
        "f1": 0.359045,
        "f1_weighted": 0.702613,
        "ap": 0.996884,
        "ap_weighted": 0.996884,
        "scores_per_experiment": [
          {
            "accuracy": 0.7135,
            "f1": 0.423088,
            "f1_weighted": 0.829133,
            "ap": 0.996855,
            "ap_weighted": 0.996855
          },
          {
            "accuracy": 0.794,
            "f1": 0.451982,
            "f1_weighted": 0.881453,
            "ap": 0.997178,
            "ap_weighted": 0.997178
          },
          {
            "accuracy": 0.32,
            "f1": 0.246146,
            "f1_weighted": 0.480214,
            "ap": 0.99677,
            "ap_weighted": 0.99677
          },
          {
            "accuracy": 0.6155,
            "f1": 0.387046,
            "f1_weighted": 0.758261,
            "ap": 0.996959,
            "ap_weighted": 0.996959
          },
          {
            "accuracy": 0.7715,
            "f1": 0.439772,
            "f1_weighted": 0.867419,
            "ap": 0.996094,
            "ap_weighted": 0.996094
          },
          {
            "accuracy": 0.707,
            "f1": 0.420709,
            "f1_weighted": 0.824693,
            "ap": 0.996829,
            "ap_weighted": 0.996829
          },
          {
            "accuracy": 0.579,
            "f1": 0.372133,
            "f1_weighted": 0.729645,
            "ap": 0.996813,
            "ap_weighted": 0.996813
          },
          {
            "accuracy": 0.2195,
            "f1": 0.182589,
            "f1_weighted": 0.354899,
            "ap": 0.996367,
            "ap_weighted": 0.996367
          },
          {
            "accuracy": 0.3655,
            "f1": 0.272524,
            "f1_weighted": 0.530516,
            "ap": 0.997452,
            "ap_weighted": 0.997452
          },
          {
            "accuracy": 0.631,
            "f1": 0.394462,
            "f1_weighted": 0.769895,
            "ap": 0.99752,
            "ap_weighted": 0.99752
          }
        ],
        "main_score": 0.57165,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.937619924545288,
  "kg_co2_emissions": null
}