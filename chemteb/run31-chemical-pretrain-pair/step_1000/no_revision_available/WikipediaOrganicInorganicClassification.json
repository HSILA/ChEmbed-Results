{
  "dataset_revision": "96d1d9b37c4693f74c46c83d63a290573f78d511",
  "task_name": "WikipediaOrganicInorganicClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.878707,
        "f1": 0.876321,
        "f1_weighted": 0.877978,
        "ap": 0.807797,
        "ap_weighted": 0.807797,
        "scores_per_experiment": [
          {
            "accuracy": 0.904943,
            "f1": 0.902206,
            "f1_weighted": 0.904259,
            "ap": 0.855147,
            "ap_weighted": 0.855147
          },
          {
            "accuracy": 0.897338,
            "f1": 0.894652,
            "f1_weighted": 0.896763,
            "ap": 0.840303,
            "ap_weighted": 0.840303
          },
          {
            "accuracy": 0.885932,
            "f1": 0.88183,
            "f1_weighted": 0.884592,
            "ap": 0.830887,
            "ap_weighted": 0.830887
          },
          {
            "accuracy": 0.787072,
            "f1": 0.786551,
            "f1_weighted": 0.785227,
            "ap": 0.672536,
            "ap_weighted": 0.672536
          },
          {
            "accuracy": 0.847909,
            "f1": 0.839262,
            "f1_weighted": 0.84394,
            "ap": 0.78505,
            "ap_weighted": 0.78505
          },
          {
            "accuracy": 0.904943,
            "f1": 0.904145,
            "f1_weighted": 0.905242,
            "ap": 0.833293,
            "ap_weighted": 0.833293
          },
          {
            "accuracy": 0.91635,
            "f1": 0.914661,
            "f1_weighted": 0.916167,
            "ap": 0.864471,
            "ap_weighted": 0.864471
          },
          {
            "accuracy": 0.870722,
            "f1": 0.870301,
            "f1_weighted": 0.871229,
            "ap": 0.778964,
            "ap_weighted": 0.778964
          },
          {
            "accuracy": 0.901141,
            "f1": 0.899559,
            "f1_weighted": 0.901141,
            "ap": 0.836122,
            "ap_weighted": 0.836122
          },
          {
            "accuracy": 0.870722,
            "f1": 0.870044,
            "f1_weighted": 0.871222,
            "ap": 0.781198,
            "ap_weighted": 0.781198
          }
        ],
        "main_score": 0.878707,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.9140894412994385,
  "kg_co2_emissions": null
}