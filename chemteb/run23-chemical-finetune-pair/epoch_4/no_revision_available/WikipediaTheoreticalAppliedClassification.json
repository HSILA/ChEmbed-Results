{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.622751,
        "f1": 0.621425,
        "f1_weighted": 0.621488,
        "ap": 0.550363,
        "ap_weighted": 0.550363,
        "scores_per_experiment": [
          {
            "accuracy": 0.658526,
            "f1": 0.658504,
            "f1_weighted": 0.658343,
            "ap": 0.577037,
            "ap_weighted": 0.577037
          },
          {
            "accuracy": 0.619366,
            "f1": 0.618763,
            "f1_weighted": 0.61789,
            "ap": 0.547055,
            "ap_weighted": 0.547055
          },
          {
            "accuracy": 0.685176,
            "f1": 0.68509,
            "f1_weighted": 0.685389,
            "ap": 0.599933,
            "ap_weighted": 0.599933
          },
          {
            "accuracy": 0.630249,
            "f1": 0.627497,
            "f1_weighted": 0.62934,
            "ap": 0.553997,
            "ap_weighted": 0.553997
          },
          {
            "accuracy": 0.593916,
            "f1": 0.593911,
            "f1_weighted": 0.593997,
            "ap": 0.528077,
            "ap_weighted": 0.528077
          },
          {
            "accuracy": 0.631791,
            "f1": 0.631505,
            "f1_weighted": 0.630914,
            "ap": 0.556119,
            "ap_weighted": 0.556119
          },
          {
            "accuracy": 0.627849,
            "f1": 0.626563,
            "f1_weighted": 0.6253,
            "ap": 0.553599,
            "ap_weighted": 0.553599
          },
          {
            "accuracy": 0.643188,
            "f1": 0.641329,
            "f1_weighted": 0.642816,
            "ap": 0.564551,
            "ap_weighted": 0.564551
          },
          {
            "accuracy": 0.561525,
            "f1": 0.558103,
            "f1_weighted": 0.555864,
            "ap": 0.50934,
            "ap_weighted": 0.50934
          },
          {
            "accuracy": 0.575921,
            "f1": 0.572989,
            "f1_weighted": 0.575027,
            "ap": 0.513919,
            "ap_weighted": 0.513919
          }
        ],
        "main_score": 0.622751,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 30.318756580352783,
  "kg_co2_emissions": null
}