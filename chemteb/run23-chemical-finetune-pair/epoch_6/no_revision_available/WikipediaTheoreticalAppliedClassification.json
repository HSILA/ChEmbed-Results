{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.607027,
        "f1": 0.605104,
        "f1_weighted": 0.604768,
        "ap": 0.538839,
        "ap_weighted": 0.538839,
        "scores_per_experiment": [
          {
            "accuracy": 0.638817,
            "f1": 0.638537,
            "f1_weighted": 0.637957,
            "ap": 0.561488,
            "ap_weighted": 0.561488
          },
          {
            "accuracy": 0.608826,
            "f1": 0.608039,
            "f1_weighted": 0.607027,
            "ap": 0.539565,
            "ap_weighted": 0.539565
          },
          {
            "accuracy": 0.668295,
            "f1": 0.668293,
            "f1_weighted": 0.668256,
            "ap": 0.585152,
            "ap_weighted": 0.585152
          },
          {
            "accuracy": 0.614396,
            "f1": 0.610454,
            "f1_weighted": 0.61271,
            "ap": 0.541402,
            "ap_weighted": 0.541402
          },
          {
            "accuracy": 0.587061,
            "f1": 0.587055,
            "f1_weighted": 0.586963,
            "ap": 0.523558,
            "ap_weighted": 0.523558
          },
          {
            "accuracy": 0.607541,
            "f1": 0.60515,
            "f1_weighted": 0.603381,
            "ap": 0.539351,
            "ap_weighted": 0.539351
          },
          {
            "accuracy": 0.606341,
            "f1": 0.604038,
            "f1_weighted": 0.602299,
            "ap": 0.53848,
            "ap_weighted": 0.53848
          },
          {
            "accuracy": 0.620737,
            "f1": 0.619344,
            "f1_weighted": 0.62067,
            "ap": 0.546684,
            "ap_weighted": 0.546684
          },
          {
            "accuracy": 0.552099,
            "f1": 0.545435,
            "f1_weighted": 0.542266,
            "ap": 0.504584,
            "ap_weighted": 0.504584
          },
          {
            "accuracy": 0.566153,
            "f1": 0.564696,
            "f1_weighted": 0.566146,
            "ap": 0.508132,
            "ap_weighted": 0.508132
          }
        ],
        "main_score": 0.607027,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 41.365477561950684,
  "kg_co2_emissions": null
}