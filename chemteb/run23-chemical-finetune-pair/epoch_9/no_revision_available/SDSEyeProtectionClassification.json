{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.6734,
        "f1": 0.407852,
        "f1_weighted": 0.801697,
        "ap": 0.998632,
        "ap_weighted": 0.998632,
        "scores_per_experiment": [
          {
            "accuracy": 0.661,
            "f1": 0.403538,
            "f1_weighted": 0.793454,
            "ap": 0.998651,
            "ap_weighted": 0.998651
          },
          {
            "accuracy": 0.636,
            "f1": 0.392636,
            "f1_weighted": 0.775175,
            "ap": 0.998089,
            "ap_weighted": 0.998089
          },
          {
            "accuracy": 0.642,
            "f1": 0.396245,
            "f1_weighted": 0.779515,
            "ap": 0.998603,
            "ap_weighted": 0.998603
          },
          {
            "accuracy": 0.643,
            "f1": 0.397932,
            "f1_weighted": 0.780131,
            "ap": 0.999105,
            "ap_weighted": 0.999105
          },
          {
            "accuracy": 0.6655,
            "f1": 0.403843,
            "f1_weighted": 0.796822,
            "ap": 0.998163,
            "ap_weighted": 0.998163
          },
          {
            "accuracy": 0.738,
            "f1": 0.430156,
            "f1_weighted": 0.846897,
            "ap": 0.998345,
            "ap_weighted": 0.998345
          },
          {
            "accuracy": 0.722,
            "f1": 0.427879,
            "f1_weighted": 0.836039,
            "ap": 0.999303,
            "ap_weighted": 0.999303
          },
          {
            "accuracy": 0.7315,
            "f1": 0.429626,
            "f1_weighted": 0.842498,
            "ap": 0.998827,
            "ap_weighted": 0.998827
          },
          {
            "accuracy": 0.6185,
            "f1": 0.385826,
            "f1_weighted": 0.76196,
            "ap": 0.998045,
            "ap_weighted": 0.998045
          },
          {
            "accuracy": 0.6765,
            "f1": 0.410841,
            "f1_weighted": 0.804483,
            "ap": 0.999189,
            "ap_weighted": 0.999189
          }
        ],
        "main_score": 0.6734,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.188146114349365,
  "kg_co2_emissions": null
}