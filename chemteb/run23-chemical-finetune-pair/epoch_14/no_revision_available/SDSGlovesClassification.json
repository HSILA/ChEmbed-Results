{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.6917,
        "f1": 0.413473,
        "f1_weighted": 0.810579,
        "ap": 0.996768,
        "ap_weighted": 0.996768,
        "scores_per_experiment": [
          {
            "accuracy": 0.7885,
            "f1": 0.447766,
            "f1_weighted": 0.878076,
            "ap": 0.996659,
            "ap_weighted": 0.996659
          },
          {
            "accuracy": 0.7795,
            "f1": 0.444651,
            "f1_weighted": 0.87243,
            "ap": 0.996622,
            "ap_weighted": 0.996622
          },
          {
            "accuracy": 0.6615,
            "f1": 0.403728,
            "f1_weighted": 0.79264,
            "ap": 0.996647,
            "ap_weighted": 0.996647
          },
          {
            "accuracy": 0.7035,
            "f1": 0.419424,
            "f1_weighted": 0.822288,
            "ap": 0.996815,
            "ap_weighted": 0.996815
          },
          {
            "accuracy": 0.782,
            "f1": 0.445517,
            "f1_weighted": 0.874004,
            "ap": 0.996633,
            "ap_weighted": 0.996633
          },
          {
            "accuracy": 0.723,
            "f1": 0.426547,
            "f1_weighted": 0.835561,
            "ap": 0.996893,
            "ap_weighted": 0.996893
          },
          {
            "accuracy": 0.6885,
            "f1": 0.415383,
            "f1_weighted": 0.811772,
            "ap": 0.997252,
            "ap_weighted": 0.997252
          },
          {
            "accuracy": 0.53,
            "f1": 0.351165,
            "f1_weighted": 0.689078,
            "ap": 0.996617,
            "ap_weighted": 0.996617
          },
          {
            "accuracy": 0.5315,
            "f1": 0.351824,
            "f1_weighted": 0.690359,
            "ap": 0.996623,
            "ap_weighted": 0.996623
          },
          {
            "accuracy": 0.729,
            "f1": 0.428722,
            "f1_weighted": 0.839585,
            "ap": 0.996917,
            "ap_weighted": 0.996917
          }
        ],
        "main_score": 0.6917,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.204755067825317,
  "kg_co2_emissions": null
}