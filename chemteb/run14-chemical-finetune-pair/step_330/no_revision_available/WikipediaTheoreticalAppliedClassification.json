{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.630428,
        "f1": 0.629291,
        "f1_weighted": 0.629451,
        "ap": 0.555826,
        "ap_weighted": 0.555826,
        "scores_per_experiment": [
          {
            "accuracy": 0.662382,
            "f1": 0.662141,
            "f1_weighted": 0.661621,
            "ap": 0.580182,
            "ap_weighted": 0.580182
          },
          {
            "accuracy": 0.624507,
            "f1": 0.623933,
            "f1_weighted": 0.623087,
            "ap": 0.550823,
            "ap_weighted": 0.550823
          },
          {
            "accuracy": 0.690403,
            "f1": 0.690377,
            "f1_weighted": 0.69054,
            "ap": 0.604431,
            "ap_weighted": 0.604431
          },
          {
            "accuracy": 0.643273,
            "f1": 0.641008,
            "f1_weighted": 0.64265,
            "ap": 0.564647,
            "ap_weighted": 0.564647
          },
          {
            "accuracy": 0.595887,
            "f1": 0.595805,
            "f1_weighted": 0.596136,
            "ap": 0.529218,
            "ap_weighted": 0.529218
          },
          {
            "accuracy": 0.639075,
            "f1": 0.63857,
            "f1_weighted": 0.637792,
            "ap": 0.561782,
            "ap_weighted": 0.561782
          },
          {
            "accuracy": 0.640274,
            "f1": 0.639597,
            "f1_weighted": 0.638697,
            "ap": 0.562766,
            "ap_weighted": 0.562766
          },
          {
            "accuracy": 0.641731,
            "f1": 0.640335,
            "f1_weighted": 0.641625,
            "ap": 0.563337,
            "ap_weighted": 0.563337
          },
          {
            "accuracy": 0.578492,
            "f1": 0.577348,
            "f1_weighted": 0.576083,
            "ap": 0.519096,
            "ap_weighted": 0.519096
          },
          {
            "accuracy": 0.58826,
            "f1": 0.583793,
            "f1_weighted": 0.586276,
            "ap": 0.521979,
            "ap_weighted": 0.521979
          }
        ],
        "main_score": 0.630428,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.74720859527588,
  "kg_co2_emissions": null
}