{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.631688,
        "f1": 0.630497,
        "f1_weighted": 0.630723,
        "ap": 0.556786,
        "ap_weighted": 0.556786,
        "scores_per_experiment": [
          {
            "accuracy": 0.664096,
            "f1": 0.663886,
            "f1_weighted": 0.663401,
            "ap": 0.581585,
            "ap_weighted": 0.581585
          },
          {
            "accuracy": 0.624679,
            "f1": 0.624053,
            "f1_weighted": 0.62317,
            "ap": 0.550976,
            "ap_weighted": 0.550976
          },
          {
            "accuracy": 0.691431,
            "f1": 0.69139,
            "f1_weighted": 0.691595,
            "ap": 0.6054,
            "ap_weighted": 0.6054
          },
          {
            "accuracy": 0.646101,
            "f1": 0.643494,
            "f1_weighted": 0.645249,
            "ap": 0.567044,
            "ap_weighted": 0.567044
          },
          {
            "accuracy": 0.598886,
            "f1": 0.598723,
            "f1_weighted": 0.599189,
            "ap": 0.531203,
            "ap_weighted": 0.531203
          },
          {
            "accuracy": 0.63916,
            "f1": 0.638658,
            "f1_weighted": 0.637883,
            "ap": 0.561847,
            "ap_weighted": 0.561847
          },
          {
            "accuracy": 0.642931,
            "f1": 0.642474,
            "f1_weighted": 0.641738,
            "ap": 0.564742,
            "ap_weighted": 0.564742
          },
          {
            "accuracy": 0.642074,
            "f1": 0.640577,
            "f1_weighted": 0.641913,
            "ap": 0.56362,
            "ap_weighted": 0.56362
          },
          {
            "accuracy": 0.579092,
            "f1": 0.578071,
            "f1_weighted": 0.576876,
            "ap": 0.519412,
            "ap_weighted": 0.519412
          },
          {
            "accuracy": 0.588432,
            "f1": 0.583647,
            "f1_weighted": 0.586217,
            "ap": 0.522029,
            "ap_weighted": 0.522029
          }
        ],
        "main_score": 0.631688,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.86416482925415,
  "kg_co2_emissions": null
}