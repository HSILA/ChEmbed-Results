{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.666,
        "f1": 0.404657,
        "f1_weighted": 0.795499,
        "ap": 0.998613,
        "ap_weighted": 0.998613,
        "scores_per_experiment": [
          {
            "accuracy": 0.6705,
            "f1": 0.407137,
            "f1_weighted": 0.800305,
            "ap": 0.998675,
            "ap_weighted": 0.998675
          },
          {
            "accuracy": 0.6275,
            "f1": 0.389344,
            "f1_weighted": 0.768792,
            "ap": 0.998068,
            "ap_weighted": 0.998068
          },
          {
            "accuracy": 0.615,
            "f1": 0.38565,
            "f1_weighted": 0.759141,
            "ap": 0.998535,
            "ap_weighted": 0.998535
          },
          {
            "accuracy": 0.654,
            "f1": 0.40221,
            "f1_weighted": 0.788236,
            "ap": 0.999133,
            "ap_weighted": 0.999133
          },
          {
            "accuracy": 0.6575,
            "f1": 0.402204,
            "f1_weighted": 0.79091,
            "ap": 0.998642,
            "ap_weighted": 0.998642
          },
          {
            "accuracy": 0.774,
            "f1": 0.442744,
            "f1_weighted": 0.87024,
            "ap": 0.998435,
            "ap_weighted": 0.998435
          },
          {
            "accuracy": 0.7195,
            "f1": 0.425275,
            "f1_weighted": 0.834435,
            "ap": 0.998797,
            "ap_weighted": 0.998797
          },
          {
            "accuracy": 0.7435,
            "f1": 0.433949,
            "f1_weighted": 0.850451,
            "ap": 0.998857,
            "ap_weighted": 0.998857
          },
          {
            "accuracy": 0.5615,
            "f1": 0.363749,
            "f1_weighted": 0.716686,
            "ap": 0.998401,
            "ap_weighted": 0.998401
          },
          {
            "accuracy": 0.637,
            "f1": 0.394304,
            "f1_weighted": 0.775793,
            "ap": 0.998591,
            "ap_weighted": 0.998591
          }
        ],
        "main_score": 0.666,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.287028789520264,
  "kg_co2_emissions": null
}