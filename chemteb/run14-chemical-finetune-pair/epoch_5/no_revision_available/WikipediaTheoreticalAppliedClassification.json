{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.628646,
        "f1": 0.627352,
        "f1_weighted": 0.627475,
        "ap": 0.554535,
        "ap_weighted": 0.554535,
        "scores_per_experiment": [
          {
            "accuracy": 0.662039,
            "f1": 0.661901,
            "f1_weighted": 0.661507,
            "ap": 0.579905,
            "ap_weighted": 0.579905
          },
          {
            "accuracy": 0.625278,
            "f1": 0.624698,
            "f1_weighted": 0.623848,
            "ap": 0.551398,
            "ap_weighted": 0.551398
          },
          {
            "accuracy": 0.687489,
            "f1": 0.687481,
            "f1_weighted": 0.687575,
            "ap": 0.60177,
            "ap_weighted": 0.60177
          },
          {
            "accuracy": 0.637618,
            "f1": 0.635144,
            "f1_weighted": 0.636874,
            "ap": 0.559984,
            "ap_weighted": 0.559984
          },
          {
            "accuracy": 0.596829,
            "f1": 0.596774,
            "f1_weighted": 0.597046,
            "ap": 0.529931,
            "ap_weighted": 0.529931
          },
          {
            "accuracy": 0.638218,
            "f1": 0.637744,
            "f1_weighted": 0.63699,
            "ap": 0.561112,
            "ap_weighted": 0.561112
          },
          {
            "accuracy": 0.636161,
            "f1": 0.635235,
            "f1_weighted": 0.634177,
            "ap": 0.559708,
            "ap_weighted": 0.559708
          },
          {
            "accuracy": 0.643873,
            "f1": 0.642001,
            "f1_weighted": 0.643492,
            "ap": 0.565119,
            "ap_weighted": 0.565119
          },
          {
            "accuracy": 0.573436,
            "f1": 0.571309,
            "f1_weighted": 0.56957,
            "ap": 0.51633,
            "ap_weighted": 0.51633
          },
          {
            "accuracy": 0.585518,
            "f1": 0.58123,
            "f1_weighted": 0.58367,
            "ap": 0.520094,
            "ap_weighted": 0.520094
          }
        ],
        "main_score": 0.628646,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.726417779922485,
  "kg_co2_emissions": null
}