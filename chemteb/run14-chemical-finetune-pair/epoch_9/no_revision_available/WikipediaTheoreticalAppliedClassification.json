{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.627386,
        "f1": 0.626083,
        "f1_weighted": 0.626164,
        "ap": 0.553588,
        "ap_weighted": 0.553588,
        "scores_per_experiment": [
          {
            "accuracy": 0.659983,
            "f1": 0.659868,
            "f1_weighted": 0.659509,
            "ap": 0.578225,
            "ap_weighted": 0.578225
          },
          {
            "accuracy": 0.62665,
            "f1": 0.626096,
            "f1_weighted": 0.625268,
            "ap": 0.552403,
            "ap_weighted": 0.552403
          },
          {
            "accuracy": 0.686632,
            "f1": 0.686628,
            "f1_weighted": 0.686697,
            "ap": 0.60099,
            "ap_weighted": 0.60099
          },
          {
            "accuracy": 0.634105,
            "f1": 0.631746,
            "f1_weighted": 0.633443,
            "ap": 0.557122,
            "ap_weighted": 0.557122
          },
          {
            "accuracy": 0.596058,
            "f1": 0.596025,
            "f1_weighted": 0.596236,
            "ap": 0.529448,
            "ap_weighted": 0.529448
          },
          {
            "accuracy": 0.637361,
            "f1": 0.636826,
            "f1_weighted": 0.636023,
            "ap": 0.56048,
            "ap_weighted": 0.56048
          },
          {
            "accuracy": 0.633933,
            "f1": 0.632924,
            "f1_weighted": 0.631815,
            "ap": 0.558051,
            "ap_weighted": 0.558051
          },
          {
            "accuracy": 0.642416,
            "f1": 0.640585,
            "f1_weighted": 0.642063,
            "ap": 0.563913,
            "ap_weighted": 0.563913
          },
          {
            "accuracy": 0.571123,
            "f1": 0.568574,
            "f1_weighted": 0.566664,
            "ap": 0.515033,
            "ap_weighted": 0.515033
          },
          {
            "accuracy": 0.585604,
            "f1": 0.581555,
            "f1_weighted": 0.583925,
            "ap": 0.520214,
            "ap_weighted": 0.520214
          }
        ],
        "main_score": 0.627386,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.634614944458008,
  "kg_co2_emissions": null
}