{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.6544,
        "f1": 0.39859,
        "f1_weighted": 0.785663,
        "ap": 0.998235,
        "ap_weighted": 0.998235,
        "scores_per_experiment": [
          {
            "accuracy": 0.7355,
            "f1": 0.427462,
            "f1_weighted": 0.845319,
            "ap": 0.99784,
            "ap_weighted": 0.99784
          },
          {
            "accuracy": 0.577,
            "f1": 0.370227,
            "f1_weighted": 0.729283,
            "ap": 0.99844,
            "ap_weighted": 0.99844
          },
          {
            "accuracy": 0.6375,
            "f1": 0.394499,
            "f1_weighted": 0.776166,
            "ap": 0.998592,
            "ap_weighted": 0.998592
          },
          {
            "accuracy": 0.5935,
            "f1": 0.378124,
            "f1_weighted": 0.742268,
            "ap": 0.998981,
            "ap_weighted": 0.998981
          },
          {
            "accuracy": 0.7375,
            "f1": 0.429979,
            "f1_weighted": 0.846566,
            "ap": 0.998343,
            "ap_weighted": 0.998343
          },
          {
            "accuracy": 0.7465,
            "f1": 0.433149,
            "f1_weighted": 0.852496,
            "ap": 0.998366,
            "ap_weighted": 0.998366
          },
          {
            "accuracy": 0.6275,
            "f1": 0.389344,
            "f1_weighted": 0.768792,
            "ap": 0.998068,
            "ap_weighted": 0.998068
          },
          {
            "accuracy": 0.783,
            "f1": 0.445863,
            "f1_weighted": 0.875929,
            "ap": 0.998457,
            "ap_weighted": 0.998457
          },
          {
            "accuracy": 0.5615,
            "f1": 0.362717,
            "f1_weighted": 0.71686,
            "ap": 0.997903,
            "ap_weighted": 0.997903
          },
          {
            "accuracy": 0.5445,
            "f1": 0.354536,
            "f1_weighted": 0.702949,
            "ap": 0.997363,
            "ap_weighted": 0.997363
          }
        ],
        "main_score": 0.6544,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.163328886032104,
  "kg_co2_emissions": null
}