{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.620317,
        "f1": 0.616734,
        "f1_weighted": 0.617754,
        "ap": 0.547297,
        "ap_weighted": 0.547297,
        "scores_per_experiment": [
          {
            "accuracy": 0.642245,
            "f1": 0.641646,
            "f1_weighted": 0.640803,
            "ap": 0.564259,
            "ap_weighted": 0.564259
          },
          {
            "accuracy": 0.61054,
            "f1": 0.610483,
            "f1_weighted": 0.610754,
            "ap": 0.539725,
            "ap_weighted": 0.539725
          },
          {
            "accuracy": 0.662725,
            "f1": 0.66177,
            "f1_weighted": 0.662805,
            "ap": 0.580898,
            "ap_weighted": 0.580898
          },
          {
            "accuracy": 0.620223,
            "f1": 0.613774,
            "f1_weighted": 0.616648,
            "ap": 0.545818,
            "ap_weighted": 0.545818
          },
          {
            "accuracy": 0.620737,
            "f1": 0.617954,
            "f1_weighted": 0.619832,
            "ap": 0.546461,
            "ap_weighted": 0.546461
          },
          {
            "accuracy": 0.621851,
            "f1": 0.620845,
            "f1_weighted": 0.619721,
            "ap": 0.54907,
            "ap_weighted": 0.54907
          },
          {
            "accuracy": 0.627506,
            "f1": 0.627504,
            "f1_weighted": 0.627447,
            "ap": 0.552562,
            "ap_weighted": 0.552562
          },
          {
            "accuracy": 0.645673,
            "f1": 0.644292,
            "f1_weighted": 0.645568,
            "ap": 0.566579,
            "ap_weighted": 0.566579
          },
          {
            "accuracy": 0.577035,
            "f1": 0.576543,
            "f1_weighted": 0.575711,
            "ap": 0.517668,
            "ap_weighted": 0.517668
          },
          {
            "accuracy": 0.574636,
            "f1": 0.552527,
            "f1_weighted": 0.558255,
            "ap": 0.509934,
            "ap_weighted": 0.509934
          }
        ],
        "main_score": 0.620317,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.94840669631958,
  "kg_co2_emissions": null
}