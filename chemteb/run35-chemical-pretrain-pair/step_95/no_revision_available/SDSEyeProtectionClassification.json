{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.64645,
        "f1": 0.396846,
        "f1_weighted": 0.780959,
        "ap": 0.998465,
        "ap_weighted": 0.998465,
        "scores_per_experiment": [
          {
            "accuracy": 0.6835,
            "f1": 0.410526,
            "f1_weighted": 0.809658,
            "ap": 0.998208,
            "ap_weighted": 0.998208
          },
          {
            "accuracy": 0.5865,
            "f1": 0.374143,
            "f1_weighted": 0.736882,
            "ap": 0.998464,
            "ap_weighted": 0.998464
          },
          {
            "accuracy": 0.602,
            "f1": 0.380444,
            "f1_weighted": 0.749086,
            "ap": 0.998503,
            "ap_weighted": 0.998503
          },
          {
            "accuracy": 0.5845,
            "f1": 0.374416,
            "f1_weighted": 0.735129,
            "ap": 0.998959,
            "ap_weighted": 0.998959
          },
          {
            "accuracy": 0.74,
            "f1": 0.432691,
            "f1_weighted": 0.848143,
            "ap": 0.998849,
            "ap_weighted": 0.998849
          },
          {
            "accuracy": 0.7335,
            "f1": 0.430348,
            "f1_weighted": 0.843831,
            "ap": 0.998832,
            "ap_weighted": 0.998832
          },
          {
            "accuracy": 0.619,
            "f1": 0.386023,
            "f1_weighted": 0.762342,
            "ap": 0.998047,
            "ap_weighted": 0.998047
          },
          {
            "accuracy": 0.7375,
            "f1": 0.431791,
            "f1_weighted": 0.846488,
            "ap": 0.998842,
            "ap_weighted": 0.998842
          },
          {
            "accuracy": 0.586,
            "f1": 0.373938,
            "f1_weighted": 0.736484,
            "ap": 0.998463,
            "ap_weighted": 0.998463
          },
          {
            "accuracy": 0.592,
            "f1": 0.374137,
            "f1_weighted": 0.74155,
            "ap": 0.997481,
            "ap_weighted": 0.997481
          }
        ],
        "main_score": 0.64645,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.091092824935913,
  "kg_co2_emissions": null
}