{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.64535,
        "f1": 0.392234,
        "f1_weighted": 0.766029,
        "ap": 0.99708,
        "ap_weighted": 0.99708,
        "scores_per_experiment": [
          {
            "accuracy": 0.8185,
            "f1": 0.458144,
            "f1_weighted": 0.896492,
            "ap": 0.996779,
            "ap_weighted": 0.996779
          },
          {
            "accuracy": 0.7765,
            "f1": 0.443612,
            "f1_weighted": 0.870535,
            "ap": 0.99661,
            "ap_weighted": 0.99661
          },
          {
            "accuracy": 0.5495,
            "f1": 0.360637,
            "f1_weighted": 0.705351,
            "ap": 0.997193,
            "ap_weighted": 0.997193
          },
          {
            "accuracy": 0.7245,
            "f1": 0.428802,
            "f1_weighted": 0.836491,
            "ap": 0.997397,
            "ap_weighted": 0.997397
          },
          {
            "accuracy": 0.831,
            "f1": 0.46531,
            "f1_weighted": 0.903961,
            "ap": 0.997326,
            "ap_weighted": 0.997326
          },
          {
            "accuracy": 0.7205,
            "f1": 0.427324,
            "f1_weighted": 0.833796,
            "ap": 0.997381,
            "ap_weighted": 0.997381
          },
          {
            "accuracy": 0.5975,
            "f1": 0.382014,
            "f1_weighted": 0.744016,
            "ap": 0.997884,
            "ap_weighted": 0.997884
          },
          {
            "accuracy": 0.2705,
            "f1": 0.215625,
            "f1_weighted": 0.421432,
            "ap": 0.996074,
            "ap_weighted": 0.996074
          },
          {
            "accuracy": 0.4555,
            "f1": 0.317626,
            "f1_weighted": 0.621899,
            "ap": 0.996815,
            "ap_weighted": 0.996815
          },
          {
            "accuracy": 0.7095,
            "f1": 0.423245,
            "f1_weighted": 0.826318,
            "ap": 0.997337,
            "ap_weighted": 0.997337
          }
        ],
        "main_score": 0.64535,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.197187900543213,
  "kg_co2_emissions": null
}