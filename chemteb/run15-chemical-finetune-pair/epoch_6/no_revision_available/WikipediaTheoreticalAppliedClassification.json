{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.631208,
        "f1": 0.629432,
        "f1_weighted": 0.629801,
        "ap": 0.556378,
        "ap_weighted": 0.556378,
        "scores_per_experiment": [
          {
            "accuracy": 0.658012,
            "f1": 0.657993,
            "f1_weighted": 0.65814,
            "ap": 0.576634,
            "ap_weighted": 0.576634
          },
          {
            "accuracy": 0.620223,
            "f1": 0.620221,
            "f1_weighted": 0.620176,
            "ap": 0.547083,
            "ap_weighted": 0.547083
          },
          {
            "accuracy": 0.692374,
            "f1": 0.692368,
            "f1_weighted": 0.692292,
            "ap": 0.605913,
            "ap_weighted": 0.605913
          },
          {
            "accuracy": 0.639332,
            "f1": 0.635924,
            "f1_weighted": 0.637952,
            "ap": 0.561437,
            "ap_weighted": 0.561437
          },
          {
            "accuracy": 0.598115,
            "f1": 0.598052,
            "f1_weighted": 0.598341,
            "ap": 0.530817,
            "ap_weighted": 0.530817
          },
          {
            "accuracy": 0.635047,
            "f1": 0.634535,
            "f1_weighted": 0.633747,
            "ap": 0.558706,
            "ap_weighted": 0.558706
          },
          {
            "accuracy": 0.639075,
            "f1": 0.637764,
            "f1_weighted": 0.636509,
            "ap": 0.562037,
            "ap_weighted": 0.562037
          },
          {
            "accuracy": 0.643702,
            "f1": 0.638999,
            "f1_weighted": 0.641371,
            "ap": 0.565248,
            "ap_weighted": 0.565248
          },
          {
            "accuracy": 0.57635,
            "f1": 0.574268,
            "f1_weighted": 0.572554,
            "ap": 0.518189,
            "ap_weighted": 0.518189
          },
          {
            "accuracy": 0.609854,
            "f1": 0.604199,
            "f1_weighted": 0.606923,
            "ap": 0.537714,
            "ap_weighted": 0.537714
          }
        ],
        "main_score": 0.631208,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.144269466400146,
  "kg_co2_emissions": null
}