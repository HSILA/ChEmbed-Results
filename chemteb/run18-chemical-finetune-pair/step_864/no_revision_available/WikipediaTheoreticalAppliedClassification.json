{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.603565,
        "f1": 0.600083,
        "f1_weighted": 0.599983,
        "ap": 0.535934,
        "ap_weighted": 0.535934,
        "scores_per_experiment": [
          {
            "accuracy": 0.623308,
            "f1": 0.622381,
            "f1_weighted": 0.623458,
            "ap": 0.548772,
            "ap_weighted": 0.548772
          },
          {
            "accuracy": 0.601371,
            "f1": 0.601044,
            "f1_weighted": 0.600387,
            "ap": 0.533976,
            "ap_weighted": 0.533976
          },
          {
            "accuracy": 0.655356,
            "f1": 0.655122,
            "f1_weighted": 0.654604,
            "ap": 0.574492,
            "ap_weighted": 0.574492
          },
          {
            "accuracy": 0.61491,
            "f1": 0.610455,
            "f1_weighted": 0.612854,
            "ap": 0.541745,
            "ap_weighted": 0.541745
          },
          {
            "accuracy": 0.582862,
            "f1": 0.582854,
            "f1_weighted": 0.582747,
            "ap": 0.520747,
            "ap_weighted": 0.520747
          },
          {
            "accuracy": 0.588432,
            "f1": 0.581415,
            "f1_weighted": 0.578294,
            "ap": 0.52765,
            "ap_weighted": 0.52765
          },
          {
            "accuracy": 0.60497,
            "f1": 0.598862,
            "f1_weighted": 0.596012,
            "ap": 0.538598,
            "ap_weighted": 0.538598
          },
          {
            "accuracy": 0.62048,
            "f1": 0.617146,
            "f1_weighted": 0.619203,
            "ap": 0.546201,
            "ap_weighted": 0.546201
          },
          {
            "accuracy": 0.558955,
            "f1": 0.554391,
            "f1_weighted": 0.551794,
            "ap": 0.508146,
            "ap_weighted": 0.508146
          },
          {
            "accuracy": 0.585004,
            "f1": 0.577165,
            "f1_weighted": 0.58048,
            "ap": 0.519014,
            "ap_weighted": 0.519014
          }
        ],
        "main_score": 0.603565,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.749289751052856,
  "kg_co2_emissions": null
}