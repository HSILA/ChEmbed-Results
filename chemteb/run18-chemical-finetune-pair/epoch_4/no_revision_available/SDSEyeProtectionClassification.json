{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.65455,
        "f1": 0.400173,
        "f1_weighted": 0.788038,
        "ap": 0.998435,
        "ap_weighted": 0.998435,
        "scores_per_experiment": [
          {
            "accuracy": 0.6675,
            "f1": 0.404591,
            "f1_weighted": 0.798262,
            "ap": 0.998168,
            "ap_weighted": 0.998168
          },
          {
            "accuracy": 0.5985,
            "f1": 0.377886,
            "f1_weighted": 0.746502,
            "ap": 0.997995,
            "ap_weighted": 0.997995
          },
          {
            "accuracy": 0.6765,
            "f1": 0.409395,
            "f1_weighted": 0.804591,
            "ap": 0.99869,
            "ap_weighted": 0.99869
          },
          {
            "accuracy": 0.629,
            "f1": 0.392425,
            "f1_weighted": 0.769656,
            "ap": 0.99907,
            "ap_weighted": 0.99907
          },
          {
            "accuracy": 0.6725,
            "f1": 0.406455,
            "f1_weighted": 0.801847,
            "ap": 0.998181,
            "ap_weighted": 0.998181
          },
          {
            "accuracy": 0.7275,
            "f1": 0.426436,
            "f1_weighted": 0.839905,
            "ap": 0.998318,
            "ap_weighted": 0.998318
          },
          {
            "accuracy": 0.669,
            "f1": 0.406571,
            "f1_weighted": 0.799228,
            "ap": 0.998671,
            "ap_weighted": 0.998671
          },
          {
            "accuracy": 0.6965,
            "f1": 0.415287,
            "f1_weighted": 0.818758,
            "ap": 0.998241,
            "ap_weighted": 0.998241
          },
          {
            "accuracy": 0.5975,
            "f1": 0.378626,
            "f1_weighted": 0.745567,
            "ap": 0.998492,
            "ap_weighted": 0.998492
          },
          {
            "accuracy": 0.611,
            "f1": 0.384056,
            "f1_weighted": 0.756065,
            "ap": 0.998525,
            "ap_weighted": 0.998525
          }
        ],
        "main_score": 0.65455,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.918644428253174,
  "kg_co2_emissions": null
}