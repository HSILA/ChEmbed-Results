{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.64325,
        "f1": 0.394467,
        "f1_weighted": 0.776939,
        "ap": 0.998357,
        "ap_weighted": 0.998357,
        "scores_per_experiment": [
          {
            "accuracy": 0.7145,
            "f1": 0.420121,
            "f1_weighted": 0.831219,
            "ap": 0.997788,
            "ap_weighted": 0.997788
          },
          {
            "accuracy": 0.547,
            "f1": 0.357584,
            "f1_weighted": 0.704672,
            "ap": 0.998365,
            "ap_weighted": 0.998365
          },
          {
            "accuracy": 0.622,
            "f1": 0.388425,
            "f1_weighted": 0.764488,
            "ap": 0.998553,
            "ap_weighted": 0.998553
          },
          {
            "accuracy": 0.582,
            "f1": 0.37338,
            "f1_weighted": 0.733132,
            "ap": 0.998952,
            "ap_weighted": 0.998952
          },
          {
            "accuracy": 0.7365,
            "f1": 0.427808,
            "f1_weighted": 0.845982,
            "ap": 0.997843,
            "ap_weighted": 0.997843
          },
          {
            "accuracy": 0.7605,
            "f1": 0.438049,
            "f1_weighted": 0.861598,
            "ap": 0.998401,
            "ap_weighted": 0.998401
          },
          {
            "accuracy": 0.6185,
            "f1": 0.38704,
            "f1_weighted": 0.761821,
            "ap": 0.998544,
            "ap_weighted": 0.998544
          },
          {
            "accuracy": 0.769,
            "f1": 0.443072,
            "f1_weighted": 0.866992,
            "ap": 0.998921,
            "ap_weighted": 0.998921
          },
          {
            "accuracy": 0.561,
            "f1": 0.364564,
            "f1_weighted": 0.7161,
            "ap": 0.9989,
            "ap_weighted": 0.9989
          },
          {
            "accuracy": 0.5215,
            "f1": 0.344628,
            "f1_weighted": 0.683391,
            "ap": 0.997305,
            "ap_weighted": 0.997305
          }
        ],
        "main_score": 0.64325,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.906689882278442,
  "kg_co2_emissions": null
}