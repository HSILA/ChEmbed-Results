{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.618312,
        "f1": 0.614427,
        "f1_weighted": 0.61564,
        "ap": 0.545626,
        "ap_weighted": 0.545626,
        "scores_per_experiment": [
          {
            "accuracy": 0.625278,
            "f1": 0.624908,
            "f1_weighted": 0.624228,
            "ap": 0.551279,
            "ap_weighted": 0.551279
          },
          {
            "accuracy": 0.607027,
            "f1": 0.60676,
            "f1_weighted": 0.60735,
            "ap": 0.536924,
            "ap_weighted": 0.536924
          },
          {
            "accuracy": 0.666752,
            "f1": 0.665062,
            "f1_weighted": 0.666432,
            "ap": 0.584663,
            "ap_weighted": 0.584663
          },
          {
            "accuracy": 0.619366,
            "f1": 0.611544,
            "f1_weighted": 0.614718,
            "ap": 0.545099,
            "ap_weighted": 0.545099
          },
          {
            "accuracy": 0.61611,
            "f1": 0.611582,
            "f1_weighted": 0.613997,
            "ap": 0.542672,
            "ap_weighted": 0.542672
          },
          {
            "accuracy": 0.607798,
            "f1": 0.606193,
            "f1_weighted": 0.604745,
            "ap": 0.539232,
            "ap_weighted": 0.539232
          },
          {
            "accuracy": 0.63102,
            "f1": 0.630979,
            "f1_weighted": 0.631202,
            "ap": 0.555101,
            "ap_weighted": 0.555101
          },
          {
            "accuracy": 0.62485,
            "f1": 0.62212,
            "f1_weighted": 0.623969,
            "ap": 0.549696,
            "ap_weighted": 0.549696
          },
          {
            "accuracy": 0.587918,
            "f1": 0.587654,
            "f1_weighted": 0.587054,
            "ap": 0.524659,
            "ap_weighted": 0.524659
          },
          {
            "accuracy": 0.597001,
            "f1": 0.57747,
            "f1_weighted": 0.582701,
            "ap": 0.526933,
            "ap_weighted": 0.526933
          }
        ],
        "main_score": 0.618312,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.151617765426636,
  "kg_co2_emissions": null
}