{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.610017,
        "f1": 0.607356,
        "f1_weighted": 0.608557,
        "ap": 0.539521,
        "ap_weighted": 0.539521,
        "scores_per_experiment": [
          {
            "accuracy": 0.61491,
            "f1": 0.614571,
            "f1_weighted": 0.613913,
            "ap": 0.543636,
            "ap_weighted": 0.543636
          },
          {
            "accuracy": 0.605484,
            "f1": 0.605195,
            "f1_weighted": 0.604579,
            "ap": 0.536837,
            "ap_weighted": 0.536837
          },
          {
            "accuracy": 0.665381,
            "f1": 0.661739,
            "f1_weighted": 0.66376,
            "ap": 0.584123,
            "ap_weighted": 0.584123
          },
          {
            "accuracy": 0.625364,
            "f1": 0.61944,
            "f1_weighted": 0.622174,
            "ap": 0.549985,
            "ap_weighted": 0.549985
          },
          {
            "accuracy": 0.585347,
            "f1": 0.584754,
            "f1_weighted": 0.585658,
            "ap": 0.521398,
            "ap_weighted": 0.521398
          },
          {
            "accuracy": 0.602399,
            "f1": 0.600587,
            "f1_weighted": 0.602137,
            "ap": 0.532837,
            "ap_weighted": 0.532837
          },
          {
            "accuracy": 0.624593,
            "f1": 0.624302,
            "f1_weighted": 0.624904,
            "ap": 0.549987,
            "ap_weighted": 0.549987
          },
          {
            "accuracy": 0.594002,
            "f1": 0.593914,
            "f1_weighted": 0.593569,
            "ap": 0.528554,
            "ap_weighted": 0.528554
          },
          {
            "accuracy": 0.589974,
            "f1": 0.587256,
            "f1_weighted": 0.589185,
            "ap": 0.52365,
            "ap_weighted": 0.52365
          },
          {
            "accuracy": 0.592716,
            "f1": 0.581805,
            "f1_weighted": 0.585695,
            "ap": 0.5242,
            "ap_weighted": 0.5242
          }
        ],
        "main_score": 0.610017,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.92473793029785,
  "kg_co2_emissions": null
}