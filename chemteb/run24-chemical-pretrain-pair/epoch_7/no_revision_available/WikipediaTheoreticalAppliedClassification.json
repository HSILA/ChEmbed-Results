{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.611431,
        "f1": 0.609026,
        "f1_weighted": 0.610122,
        "ap": 0.540691,
        "ap_weighted": 0.540691,
        "scores_per_experiment": [
          {
            "accuracy": 0.616624,
            "f1": 0.616363,
            "f1_weighted": 0.615788,
            "ap": 0.544819,
            "ap_weighted": 0.544819
          },
          {
            "accuracy": 0.603942,
            "f1": 0.603462,
            "f1_weighted": 0.602667,
            "ap": 0.53591,
            "ap_weighted": 0.53591
          },
          {
            "accuracy": 0.669152,
            "f1": 0.666126,
            "f1_weighted": 0.667956,
            "ap": 0.587318,
            "ap_weighted": 0.587318
          },
          {
            "accuracy": 0.628706,
            "f1": 0.623571,
            "f1_weighted": 0.626103,
            "ap": 0.552713,
            "ap_weighted": 0.552713
          },
          {
            "accuracy": 0.582605,
            "f1": 0.582121,
            "f1_weighted": 0.58294,
            "ap": 0.519624,
            "ap_weighted": 0.519624
          },
          {
            "accuracy": 0.604027,
            "f1": 0.602282,
            "f1_weighted": 0.603799,
            "ap": 0.534047,
            "ap_weighted": 0.534047
          },
          {
            "accuracy": 0.625107,
            "f1": 0.624896,
            "f1_weighted": 0.625408,
            "ap": 0.550426,
            "ap_weighted": 0.550426
          },
          {
            "accuracy": 0.594687,
            "f1": 0.594546,
            "f1_weighted": 0.59411,
            "ap": 0.529116,
            "ap_weighted": 0.529116
          },
          {
            "accuracy": 0.593059,
            "f1": 0.590553,
            "f1_weighted": 0.592398,
            "ap": 0.525897,
            "ap_weighted": 0.525897
          },
          {
            "accuracy": 0.596401,
            "f1": 0.58634,
            "f1_weighted": 0.590055,
            "ap": 0.527039,
            "ap_weighted": 0.527039
          }
        ],
        "main_score": 0.611431,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.92000198364258,
  "kg_co2_emissions": null
}