{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.68055,
        "f1": 0.408054,
        "f1_weighted": 0.797539,
        "ap": 0.997121,
        "ap_weighted": 0.997121,
        "scores_per_experiment": [
          {
            "accuracy": 0.865,
            "f1": 0.467464,
            "f1_weighted": 0.923894,
            "ap": 0.995972,
            "ap_weighted": 0.995972
          },
          {
            "accuracy": 0.768,
            "f1": 0.442715,
            "f1_weighted": 0.865075,
            "ap": 0.997074,
            "ap_weighted": 0.997074
          },
          {
            "accuracy": 0.6675,
            "f1": 0.407407,
            "f1_weighted": 0.796859,
            "ap": 0.997168,
            "ap_weighted": 0.997168
          },
          {
            "accuracy": 0.752,
            "f1": 0.438903,
            "f1_weighted": 0.854689,
            "ap": 0.997507,
            "ap_weighted": 0.997507
          },
          {
            "accuracy": 0.835,
            "f1": 0.466777,
            "f1_weighted": 0.90634,
            "ap": 0.997342,
            "ap_weighted": 0.997342
          },
          {
            "accuracy": 0.678,
            "f1": 0.409958,
            "f1_weighted": 0.804465,
            "ap": 0.996713,
            "ap_weighted": 0.996713
          },
          {
            "accuracy": 0.635,
            "f1": 0.397308,
            "f1_weighted": 0.772771,
            "ap": 0.998035,
            "ap_weighted": 0.998035
          },
          {
            "accuracy": 0.4265,
            "f1": 0.304022,
            "f1_weighted": 0.593649,
            "ap": 0.997197,
            "ap_weighted": 0.997197
          },
          {
            "accuracy": 0.4565,
            "f1": 0.31811,
            "f1_weighted": 0.622844,
            "ap": 0.996819,
            "ap_weighted": 0.996819
          },
          {
            "accuracy": 0.722,
            "f1": 0.427879,
            "f1_weighted": 0.834808,
            "ap": 0.997387,
            "ap_weighted": 0.997387
          }
        ],
        "main_score": 0.68055,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.030325651168823,
  "kg_co2_emissions": null
}