{
  "dataset_revision": "7d8df44e588b6143d4856c781f72f919fa0599a7",
  "task_name": "WikipediaSolidStateColloidalClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.793018,
        "f1": 0.790691,
        "f1_weighted": 0.791902,
        "ap": 0.772096,
        "ap_weighted": 0.772096,
        "scores_per_experiment": [
          {
            "accuracy": 0.788288,
            "f1": 0.788181,
            "f1_weighted": 0.788675,
            "ap": 0.779147,
            "ap_weighted": 0.779147
          },
          {
            "accuracy": 0.664414,
            "f1": 0.661237,
            "f1_weighted": 0.657838,
            "ap": 0.683403,
            "ap_weighted": 0.683403
          },
          {
            "accuracy": 0.804054,
            "f1": 0.802684,
            "f1_weighted": 0.804387,
            "ap": 0.779312,
            "ap_weighted": 0.779312
          },
          {
            "accuracy": 0.828829,
            "f1": 0.824206,
            "f1_weighted": 0.827159,
            "ap": 0.785277,
            "ap_weighted": 0.785277
          },
          {
            "accuracy": 0.79955,
            "f1": 0.799378,
            "f1_weighted": 0.799986,
            "ap": 0.789216,
            "ap_weighted": 0.789216
          },
          {
            "accuracy": 0.822072,
            "f1": 0.819299,
            "f1_weighted": 0.821618,
            "ap": 0.78749,
            "ap_weighted": 0.78749
          },
          {
            "accuracy": 0.817568,
            "f1": 0.808424,
            "f1_weighted": 0.81276,
            "ap": 0.763238,
            "ap_weighted": 0.763238
          },
          {
            "accuracy": 0.858108,
            "f1": 0.856888,
            "f1_weighted": 0.858257,
            "ap": 0.833736,
            "ap_weighted": 0.833736
          },
          {
            "accuracy": 0.768018,
            "f1": 0.767876,
            "f1_weighted": 0.768471,
            "ap": 0.757466,
            "ap_weighted": 0.757466
          },
          {
            "accuracy": 0.779279,
            "f1": 0.778736,
            "f1_weighted": 0.779872,
            "ap": 0.762671,
            "ap_weighted": 0.762671
          }
        ],
        "main_score": 0.793018,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.588806390762329,
  "kg_co2_emissions": null
}