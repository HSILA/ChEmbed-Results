{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.611825,
        "f1": 0.608409,
        "f1_weighted": 0.609835,
        "ap": 0.540755,
        "ap_weighted": 0.540755,
        "scores_per_experiment": [
          {
            "accuracy": 0.620651,
            "f1": 0.620574,
            "f1_weighted": 0.620261,
            "ap": 0.547586,
            "ap_weighted": 0.547586
          },
          {
            "accuracy": 0.582776,
            "f1": 0.582703,
            "f1_weighted": 0.583022,
            "ap": 0.520248,
            "ap_weighted": 0.520248
          },
          {
            "accuracy": 0.670009,
            "f1": 0.667553,
            "f1_weighted": 0.669198,
            "ap": 0.587866,
            "ap_weighted": 0.587866
          },
          {
            "accuracy": 0.61928,
            "f1": 0.608835,
            "f1_weighted": 0.612516,
            "ap": 0.545034,
            "ap_weighted": 0.545034
          },
          {
            "accuracy": 0.587918,
            "f1": 0.584802,
            "f1_weighted": 0.586873,
            "ap": 0.522087,
            "ap_weighted": 0.522087
          },
          {
            "accuracy": 0.612768,
            "f1": 0.612517,
            "f1_weighted": 0.611949,
            "ap": 0.542011,
            "ap_weighted": 0.542011
          },
          {
            "accuracy": 0.613196,
            "f1": 0.613098,
            "f1_weighted": 0.613453,
            "ap": 0.541606,
            "ap_weighted": 0.541606
          },
          {
            "accuracy": 0.613967,
            "f1": 0.612961,
            "f1_weighted": 0.614098,
            "ap": 0.541654,
            "ap_weighted": 0.541654
          },
          {
            "accuracy": 0.592459,
            "f1": 0.591046,
            "f1_weighted": 0.59243,
            "ap": 0.525867,
            "ap_weighted": 0.525867
          },
          {
            "accuracy": 0.605227,
            "f1": 0.59,
            "f1_weighted": 0.59455,
            "ap": 0.533587,
            "ap_weighted": 0.533587
          }
        ],
        "main_score": 0.611825,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.970019340515137,
  "kg_co2_emissions": null
}