{
  "dataset_revision": "7d8df44e588b6143d4856c781f72f919fa0599a7",
  "task_name": "WikipediaSolidStateColloidalClassification",
  "mteb_version": "1.36.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.788514,
        "f1": 0.785946,
        "f1_weighted": 0.78703,
        "ap": 0.76989,
        "ap_weighted": 0.76989,
        "scores_per_experiment": [
          {
            "accuracy": 0.795045,
            "f1": 0.793105,
            "f1_weighted": 0.79518,
            "ap": 0.76708,
            "ap_weighted": 0.76708
          },
          {
            "accuracy": 0.657658,
            "f1": 0.65587,
            "f1_weighted": 0.653301,
            "ap": 0.67206,
            "ap_weighted": 0.67206
          },
          {
            "accuracy": 0.797297,
            "f1": 0.796239,
            "f1_weighted": 0.79776,
            "ap": 0.775285,
            "ap_weighted": 0.775285
          },
          {
            "accuracy": 0.835586,
            "f1": 0.830756,
            "f1_weighted": 0.833718,
            "ap": 0.790336,
            "ap_weighted": 0.790336
          },
          {
            "accuracy": 0.754505,
            "f1": 0.754443,
            "f1_weighted": 0.754042,
            "ap": 0.754201,
            "ap_weighted": 0.754201
          },
          {
            "accuracy": 0.835586,
            "f1": 0.834672,
            "f1_weighted": 0.835945,
            "ap": 0.814722,
            "ap_weighted": 0.814722
          },
          {
            "accuracy": 0.824324,
            "f1": 0.820355,
            "f1_weighted": 0.823121,
            "ap": 0.783929,
            "ap_weighted": 0.783929
          },
          {
            "accuracy": 0.846847,
            "f1": 0.845717,
            "f1_weighted": 0.847085,
            "ap": 0.823534,
            "ap_weighted": 0.823534
          },
          {
            "accuracy": 0.752252,
            "f1": 0.750015,
            "f1_weighted": 0.747565,
            "ap": 0.777139,
            "ap_weighted": 0.777139
          },
          {
            "accuracy": 0.786036,
            "f1": 0.778288,
            "f1_weighted": 0.782582,
            "ap": 0.740608,
            "ap_weighted": 0.740608
          }
        ],
        "main_score": 0.788514,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.5751287937164307,
  "kg_co2_emissions": null
}