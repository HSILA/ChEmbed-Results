{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.579572,
        "f1": 0.578001,
        "f1_weighted": 0.577519,
        "ap": 0.519662,
        "ap_weighted": 0.519662,
        "scores_per_experiment": [
          {
            "accuracy": 0.600857,
            "f1": 0.600481,
            "f1_weighted": 0.601187,
            "ap": 0.532394,
            "ap_weighted": 0.532394
          },
          {
            "accuracy": 0.593488,
            "f1": 0.593154,
            "f1_weighted": 0.592484,
            "ap": 0.528523,
            "ap_weighted": 0.528523
          },
          {
            "accuracy": 0.617138,
            "f1": 0.616891,
            "f1_weighted": 0.617451,
            "ap": 0.544385,
            "ap_weighted": 0.544385
          },
          {
            "accuracy": 0.577978,
            "f1": 0.57795,
            "f1_weighted": 0.578148,
            "ap": 0.517178,
            "ap_weighted": 0.517178
          },
          {
            "accuracy": 0.552956,
            "f1": 0.545169,
            "f1_weighted": 0.541742,
            "ap": 0.505389,
            "ap_weighted": 0.505389
          },
          {
            "accuracy": 0.579949,
            "f1": 0.578317,
            "f1_weighted": 0.576806,
            "ap": 0.520317,
            "ap_weighted": 0.520317
          },
          {
            "accuracy": 0.592888,
            "f1": 0.59213,
            "f1_weighted": 0.591118,
            "ap": 0.528456,
            "ap_weighted": 0.528456
          },
          {
            "accuracy": 0.595116,
            "f1": 0.592103,
            "f1_weighted": 0.594121,
            "ap": 0.527222,
            "ap_weighted": 0.527222
          },
          {
            "accuracy": 0.551071,
            "f1": 0.549555,
            "f1_weighted": 0.54805,
            "ap": 0.502085,
            "ap_weighted": 0.502085
          },
          {
            "accuracy": 0.534276,
            "f1": 0.534256,
            "f1_weighted": 0.534079,
            "ap": 0.490672,
            "ap_weighted": 0.490672
          }
        ],
        "main_score": 0.579572,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 151.9892966747284,
  "kg_co2_emissions": null
}