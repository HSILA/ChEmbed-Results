{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.68975,
        "f1": 0.412326,
        "f1_weighted": 0.80409,
        "ap": 0.997258,
        "ap_weighted": 0.997258,
        "scores_per_experiment": [
          {
            "accuracy": 0.8565,
            "f1": 0.468183,
            "f1_weighted": 0.918985,
            "ap": 0.996434,
            "ap_weighted": 0.996434
          },
          {
            "accuracy": 0.7795,
            "f1": 0.446814,
            "f1_weighted": 0.872378,
            "ap": 0.99712,
            "ap_weighted": 0.99712
          },
          {
            "accuracy": 0.619,
            "f1": 0.389649,
            "f1_weighted": 0.760801,
            "ap": 0.997472,
            "ap_weighted": 0.997472
          },
          {
            "accuracy": 0.743,
            "f1": 0.435606,
            "f1_weighted": 0.848797,
            "ap": 0.997471,
            "ap_weighted": 0.997471
          },
          {
            "accuracy": 0.8405,
            "f1": 0.468807,
            "f1_weighted": 0.909595,
            "ap": 0.997364,
            "ap_weighted": 0.997364
          },
          {
            "accuracy": 0.699,
            "f1": 0.417767,
            "f1_weighted": 0.819182,
            "ap": 0.996797,
            "ap_weighted": 0.996797
          },
          {
            "accuracy": 0.6495,
            "f1": 0.403093,
            "f1_weighted": 0.783538,
            "ap": 0.998093,
            "ap_weighted": 0.998093
          },
          {
            "accuracy": 0.4215,
            "f1": 0.300788,
            "f1_weighted": 0.588986,
            "ap": 0.996679,
            "ap_weighted": 0.996679
          },
          {
            "accuracy": 0.4915,
            "f1": 0.334676,
            "f1_weighted": 0.655107,
            "ap": 0.99696,
            "ap_weighted": 0.99696
          },
          {
            "accuracy": 0.7975,
            "f1": 0.457872,
            "f1_weighted": 0.883533,
            "ap": 0.998188,
            "ap_weighted": 0.998188
          }
        ],
        "main_score": 0.68975,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.992993354797363,
  "kg_co2_emissions": null
}