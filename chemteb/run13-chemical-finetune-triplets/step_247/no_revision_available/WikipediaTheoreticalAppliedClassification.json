{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.643676,
        "f1": 0.641344,
        "f1_weighted": 0.641802,
        "ap": 0.565867,
        "ap_weighted": 0.565867,
        "scores_per_experiment": [
          {
            "accuracy": 0.676093,
            "f1": 0.675811,
            "f1_weighted": 0.675261,
            "ap": 0.591535,
            "ap_weighted": 0.591535
          },
          {
            "accuracy": 0.630677,
            "f1": 0.62902,
            "f1_weighted": 0.627592,
            "ap": 0.55582,
            "ap_weighted": 0.55582
          },
          {
            "accuracy": 0.699572,
            "f1": 0.699554,
            "f1_weighted": 0.69942,
            "ap": 0.612266,
            "ap_weighted": 0.612266
          },
          {
            "accuracy": 0.653385,
            "f1": 0.647942,
            "f1_weighted": 0.650463,
            "ap": 0.573837,
            "ap_weighted": 0.573837
          },
          {
            "accuracy": 0.623136,
            "f1": 0.621912,
            "f1_weighted": 0.623151,
            "ap": 0.548569,
            "ap_weighted": 0.548569
          },
          {
            "accuracy": 0.645844,
            "f1": 0.643576,
            "f1_weighted": 0.641938,
            "ap": 0.567424,
            "ap_weighted": 0.567424
          },
          {
            "accuracy": 0.652014,
            "f1": 0.651779,
            "f1_weighted": 0.651258,
            "ap": 0.571818,
            "ap_weighted": 0.571818
          },
          {
            "accuracy": 0.655184,
            "f1": 0.653792,
            "f1_weighted": 0.655056,
            "ap": 0.574557,
            "ap_weighted": 0.574557
          },
          {
            "accuracy": 0.598886,
            "f1": 0.598886,
            "f1_weighted": 0.598884,
            "ap": 0.531625,
            "ap_weighted": 0.531625
          },
          {
            "accuracy": 0.601971,
            "f1": 0.591168,
            "f1_weighted": 0.594995,
            "ap": 0.531216,
            "ap_weighted": 0.531216
          }
        ],
        "main_score": 0.643676,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.401418209075928,
  "kg_co2_emissions": null
}