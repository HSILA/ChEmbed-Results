{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.68675,
        "f1": 0.411606,
        "f1_weighted": 0.804215,
        "ap": 0.997196,
        "ap_weighted": 0.997196,
        "scores_per_experiment": [
          {
            "accuracy": 0.846,
            "f1": 0.461491,
            "f1_weighted": 0.912891,
            "ap": 0.995896,
            "ap_weighted": 0.995896
          },
          {
            "accuracy": 0.767,
            "f1": 0.442358,
            "f1_weighted": 0.864435,
            "ap": 0.997069,
            "ap_weighted": 0.997069
          },
          {
            "accuracy": 0.601,
            "f1": 0.382329,
            "f1_weighted": 0.746903,
            "ap": 0.997399,
            "ap_weighted": 0.997399
          },
          {
            "accuracy": 0.7415,
            "f1": 0.435056,
            "f1_weighted": 0.847809,
            "ap": 0.997465,
            "ap_weighted": 0.997465
          },
          {
            "accuracy": 0.833,
            "f1": 0.466043,
            "f1_weighted": 0.905152,
            "ap": 0.997334,
            "ap_weighted": 0.997334
          },
          {
            "accuracy": 0.7045,
            "f1": 0.419792,
            "f1_weighted": 0.822976,
            "ap": 0.996819,
            "ap_weighted": 0.996819
          },
          {
            "accuracy": 0.648,
            "f1": 0.401194,
            "f1_weighted": 0.782552,
            "ap": 0.997588,
            "ap_weighted": 0.997588
          },
          {
            "accuracy": 0.464,
            "f1": 0.322506,
            "f1_weighted": 0.629644,
            "ap": 0.997348,
            "ap_weighted": 0.997348
          },
          {
            "accuracy": 0.5255,
            "f1": 0.350107,
            "f1_weighted": 0.685025,
            "ap": 0.997096,
            "ap_weighted": 0.997096
          },
          {
            "accuracy": 0.737,
            "f1": 0.435185,
            "f1_weighted": 0.844762,
            "ap": 0.997945,
            "ap_weighted": 0.997945
          }
        ],
        "main_score": 0.68675,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.017335414886475,
  "kg_co2_emissions": null
}