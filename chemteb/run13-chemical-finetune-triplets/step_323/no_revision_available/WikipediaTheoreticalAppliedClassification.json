{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.642751,
        "f1": 0.640408,
        "f1_weighted": 0.640835,
        "ap": 0.56518,
        "ap_weighted": 0.56518,
        "scores_per_experiment": [
          {
            "accuracy": 0.675921,
            "f1": 0.675584,
            "f1_weighted": 0.674983,
            "ap": 0.591374,
            "ap_weighted": 0.591374
          },
          {
            "accuracy": 0.630763,
            "f1": 0.62877,
            "f1_weighted": 0.627204,
            "ap": 0.555981,
            "ap_weighted": 0.555981
          },
          {
            "accuracy": 0.698115,
            "f1": 0.698093,
            "f1_weighted": 0.697946,
            "ap": 0.610942,
            "ap_weighted": 0.610942
          },
          {
            "accuracy": 0.652442,
            "f1": 0.647129,
            "f1_weighted": 0.649622,
            "ap": 0.572971,
            "ap_weighted": 0.572971
          },
          {
            "accuracy": 0.622194,
            "f1": 0.621029,
            "f1_weighted": 0.622239,
            "ap": 0.547856,
            "ap_weighted": 0.547856
          },
          {
            "accuracy": 0.644302,
            "f1": 0.642053,
            "f1_weighted": 0.640419,
            "ap": 0.56624,
            "ap_weighted": 0.56624
          },
          {
            "accuracy": 0.651243,
            "f1": 0.65099,
            "f1_weighted": 0.650449,
            "ap": 0.571208,
            "ap_weighted": 0.571208
          },
          {
            "accuracy": 0.65587,
            "f1": 0.654095,
            "f1_weighted": 0.655522,
            "ap": 0.57522,
            "ap_weighted": 0.57522
          },
          {
            "accuracy": 0.595201,
            "f1": 0.595193,
            "f1_weighted": 0.595085,
            "ap": 0.529154,
            "ap_weighted": 0.529154
          },
          {
            "accuracy": 0.601457,
            "f1": 0.591149,
            "f1_weighted": 0.594887,
            "ap": 0.530856,
            "ap_weighted": 0.530856
          }
        ],
        "main_score": 0.642751,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.336349725723267,
  "kg_co2_emissions": null
}