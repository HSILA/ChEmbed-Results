{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.59012,
        "f1": 0.585121,
        "f1_weighted": 0.586024,
        "ap": 0.52588,
        "ap_weighted": 0.52588,
        "scores_per_experiment": [
          {
            "accuracy": 0.612168,
            "f1": 0.610309,
            "f1_weighted": 0.608759,
            "ap": 0.542425,
            "ap_weighted": 0.542425
          },
          {
            "accuracy": 0.596144,
            "f1": 0.595106,
            "f1_weighted": 0.593925,
            "ap": 0.530856,
            "ap_weighted": 0.530856
          },
          {
            "accuracy": 0.63659,
            "f1": 0.63443,
            "f1_weighted": 0.636048,
            "ap": 0.559143,
            "ap_weighted": 0.559143
          },
          {
            "accuracy": 0.577121,
            "f1": 0.568441,
            "f1_weighted": 0.571966,
            "ap": 0.513351,
            "ap_weighted": 0.513351
          },
          {
            "accuracy": 0.572237,
            "f1": 0.569273,
            "f1_weighted": 0.567216,
            "ap": 0.515911,
            "ap_weighted": 0.515911
          },
          {
            "accuracy": 0.577806,
            "f1": 0.577608,
            "f1_weighted": 0.578135,
            "ap": 0.516717,
            "ap_weighted": 0.516717
          },
          {
            "accuracy": 0.593059,
            "f1": 0.590716,
            "f1_weighted": 0.592499,
            "ap": 0.525948,
            "ap_weighted": 0.525948
          },
          {
            "accuracy": 0.604027,
            "f1": 0.587543,
            "f1_weighted": 0.592291,
            "ap": 0.532602,
            "ap_weighted": 0.532602
          },
          {
            "accuracy": 0.529906,
            "f1": 0.526676,
            "f1_weighted": 0.524425,
            "ap": 0.490513,
            "ap_weighted": 0.490513
          },
          {
            "accuracy": 0.602142,
            "f1": 0.591109,
            "f1_weighted": 0.594977,
            "ap": 0.531333,
            "ap_weighted": 0.531333
          }
        ],
        "main_score": 0.59012,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.81451368331909,
  "kg_co2_emissions": null
}