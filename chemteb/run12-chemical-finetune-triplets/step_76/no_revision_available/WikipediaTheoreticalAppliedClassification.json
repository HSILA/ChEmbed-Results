{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.652982,
        "f1": 0.650424,
        "f1_weighted": 0.65111,
        "ap": 0.573417,
        "ap_weighted": 0.573417,
        "scores_per_experiment": [
          {
            "accuracy": 0.685518,
            "f1": 0.685405,
            "f1_weighted": 0.68506,
            "ap": 0.599673,
            "ap_weighted": 0.599673
          },
          {
            "accuracy": 0.638389,
            "f1": 0.637713,
            "f1_weighted": 0.636812,
            "ap": 0.56132,
            "ap_weighted": 0.56132
          },
          {
            "accuracy": 0.709083,
            "f1": 0.709074,
            "f1_weighted": 0.709167,
            "ap": 0.621315,
            "ap_weighted": 0.621315
          },
          {
            "accuracy": 0.664267,
            "f1": 0.657436,
            "f1_weighted": 0.660222,
            "ap": 0.584189,
            "ap_weighted": 0.584189
          },
          {
            "accuracy": 0.631191,
            "f1": 0.629912,
            "f1_weighted": 0.631165,
            "ap": 0.55486,
            "ap_weighted": 0.55486
          },
          {
            "accuracy": 0.66024,
            "f1": 0.658319,
            "f1_weighted": 0.656844,
            "ap": 0.578593,
            "ap_weighted": 0.578593
          },
          {
            "accuracy": 0.664353,
            "f1": 0.66423,
            "f1_weighted": 0.663861,
            "ap": 0.581806,
            "ap_weighted": 0.581806
          },
          {
            "accuracy": 0.656727,
            "f1": 0.65517,
            "f1_weighted": 0.656504,
            "ap": 0.575907,
            "ap_weighted": 0.575907
          },
          {
            "accuracy": 0.614482,
            "f1": 0.614412,
            "f1_weighted": 0.61471,
            "ap": 0.542593,
            "ap_weighted": 0.542593
          },
          {
            "accuracy": 0.60557,
            "f1": 0.592564,
            "f1_weighted": 0.596756,
            "ap": 0.533918,
            "ap_weighted": 0.533918
          }
        ],
        "main_score": 0.652982,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.83852982521057,
  "kg_co2_emissions": null
}