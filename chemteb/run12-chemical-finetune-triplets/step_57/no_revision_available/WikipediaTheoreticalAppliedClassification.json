{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.654859,
        "f1": 0.652273,
        "f1_weighted": 0.652985,
        "ap": 0.574945,
        "ap_weighted": 0.574945,
        "scores_per_experiment": [
          {
            "accuracy": 0.68826,
            "f1": 0.688186,
            "f1_weighted": 0.687909,
            "ap": 0.602105,
            "ap_weighted": 0.602105
          },
          {
            "accuracy": 0.640874,
            "f1": 0.640318,
            "f1_weighted": 0.639503,
            "ap": 0.563186,
            "ap_weighted": 0.563186
          },
          {
            "accuracy": 0.710197,
            "f1": 0.710179,
            "f1_weighted": 0.710311,
            "ap": 0.622426,
            "ap_weighted": 0.622426
          },
          {
            "accuracy": 0.664867,
            "f1": 0.658023,
            "f1_weighted": 0.660808,
            "ap": 0.584757,
            "ap_weighted": 0.584757
          },
          {
            "accuracy": 0.63539,
            "f1": 0.633954,
            "f1_weighted": 0.635274,
            "ap": 0.558195,
            "ap_weighted": 0.558195
          },
          {
            "accuracy": 0.661782,
            "f1": 0.659817,
            "f1_weighted": 0.658328,
            "ap": 0.579822,
            "ap_weighted": 0.579822
          },
          {
            "accuracy": 0.66521,
            "f1": 0.66505,
            "f1_weighted": 0.664629,
            "ap": 0.582506,
            "ap_weighted": 0.582506
          },
          {
            "accuracy": 0.656984,
            "f1": 0.655488,
            "f1_weighted": 0.656795,
            "ap": 0.576114,
            "ap_weighted": 0.576114
          },
          {
            "accuracy": 0.616024,
            "f1": 0.615917,
            "f1_weighted": 0.616286,
            "ap": 0.543683,
            "ap_weighted": 0.543683
          },
          {
            "accuracy": 0.608997,
            "f1": 0.595796,
            "f1_weighted": 0.600003,
            "ap": 0.536651,
            "ap_weighted": 0.536651
          }
        ],
        "main_score": 0.654859,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.368080377578735,
  "kg_co2_emissions": null
}