{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.641765,
        "f1": 0.639548,
        "f1_weighted": 0.640025,
        "ap": 0.564244,
        "ap_weighted": 0.564244,
        "scores_per_experiment": [
          {
            "accuracy": 0.674722,
            "f1": 0.674595,
            "f1_weighted": 0.674226,
            "ap": 0.590446,
            "ap_weighted": 0.590446
          },
          {
            "accuracy": 0.630763,
            "f1": 0.62926,
            "f1_weighted": 0.627901,
            "ap": 0.555836,
            "ap_weighted": 0.555836
          },
          {
            "accuracy": 0.692888,
            "f1": 0.692864,
            "f1_weighted": 0.69271,
            "ap": 0.606283,
            "ap_weighted": 0.606283
          },
          {
            "accuracy": 0.650985,
            "f1": 0.645941,
            "f1_weighted": 0.648374,
            "ap": 0.571628,
            "ap_weighted": 0.571628
          },
          {
            "accuracy": 0.619109,
            "f1": 0.617883,
            "f1_weighted": 0.619129,
            "ap": 0.545476,
            "ap_weighted": 0.545476
          },
          {
            "accuracy": 0.645244,
            "f1": 0.642947,
            "f1_weighted": 0.641298,
            "ap": 0.56697,
            "ap_weighted": 0.56697
          },
          {
            "accuracy": 0.652356,
            "f1": 0.652158,
            "f1_weighted": 0.651679,
            "ap": 0.572083,
            "ap_weighted": 0.572083
          },
          {
            "accuracy": 0.651671,
            "f1": 0.650395,
            "f1_weighted": 0.651611,
            "ap": 0.571569,
            "ap_weighted": 0.571569
          },
          {
            "accuracy": 0.597001,
            "f1": 0.596988,
            "f1_weighted": 0.597118,
            "ap": 0.530183,
            "ap_weighted": 0.530183
          },
          {
            "accuracy": 0.602913,
            "f1": 0.592449,
            "f1_weighted": 0.596209,
            "ap": 0.531967,
            "ap_weighted": 0.531967
          }
        ],
        "main_score": 0.641765,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.512227296829224,
  "kg_co2_emissions": null
}