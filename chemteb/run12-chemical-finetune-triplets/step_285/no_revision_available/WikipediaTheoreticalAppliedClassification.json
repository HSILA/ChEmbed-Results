{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.642237,
        "f1": 0.639925,
        "f1_weighted": 0.640413,
        "ap": 0.564651,
        "ap_weighted": 0.564651,
        "scores_per_experiment": [
          {
            "accuracy": 0.676264,
            "f1": 0.67611,
            "f1_weighted": 0.675705,
            "ap": 0.591733,
            "ap_weighted": 0.591733
          },
          {
            "accuracy": 0.630334,
            "f1": 0.62858,
            "f1_weighted": 0.62711,
            "ap": 0.555594,
            "ap_weighted": 0.555594
          },
          {
            "accuracy": 0.693916,
            "f1": 0.693901,
            "f1_weighted": 0.693777,
            "ap": 0.607228,
            "ap_weighted": 0.607228
          },
          {
            "accuracy": 0.650557,
            "f1": 0.645275,
            "f1_weighted": 0.647768,
            "ap": 0.571297,
            "ap_weighted": 0.571297
          },
          {
            "accuracy": 0.61928,
            "f1": 0.617979,
            "f1_weighted": 0.619263,
            "ap": 0.545588,
            "ap_weighted": 0.545588
          },
          {
            "accuracy": 0.647044,
            "f1": 0.644754,
            "f1_weighted": 0.643111,
            "ap": 0.568348,
            "ap_weighted": 0.568348
          },
          {
            "accuracy": 0.653299,
            "f1": 0.653132,
            "f1_weighted": 0.652694,
            "ap": 0.572829,
            "ap_weighted": 0.572829
          },
          {
            "accuracy": 0.652614,
            "f1": 0.651308,
            "f1_weighted": 0.652537,
            "ap": 0.572366,
            "ap_weighted": 0.572366
          },
          {
            "accuracy": 0.596144,
            "f1": 0.596131,
            "f1_weighted": 0.596264,
            "ap": 0.529581,
            "ap_weighted": 0.529581
          },
          {
            "accuracy": 0.602913,
            "f1": 0.592078,
            "f1_weighted": 0.595906,
            "ap": 0.531942,
            "ap_weighted": 0.531942
          }
        ],
        "main_score": 0.642237,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.78961992263794,
  "kg_co2_emissions": null
}