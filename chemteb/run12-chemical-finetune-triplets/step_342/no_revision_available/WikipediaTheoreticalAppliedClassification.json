{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.641877,
        "f1": 0.639647,
        "f1_weighted": 0.640127,
        "ap": 0.564361,
        "ap_weighted": 0.564361,
        "scores_per_experiment": [
          {
            "accuracy": 0.67575,
            "f1": 0.675608,
            "f1_weighted": 0.675217,
            "ap": 0.591305,
            "ap_weighted": 0.591305
          },
          {
            "accuracy": 0.63102,
            "f1": 0.629489,
            "f1_weighted": 0.628118,
            "ap": 0.556036,
            "ap_weighted": 0.556036
          },
          {
            "accuracy": 0.693231,
            "f1": 0.693213,
            "f1_weighted": 0.69308,
            "ap": 0.606609,
            "ap_weighted": 0.606609
          },
          {
            "accuracy": 0.650728,
            "f1": 0.645569,
            "f1_weighted": 0.648031,
            "ap": 0.571424,
            "ap_weighted": 0.571424
          },
          {
            "accuracy": 0.619023,
            "f1": 0.617801,
            "f1_weighted": 0.619045,
            "ap": 0.545412,
            "ap_weighted": 0.545412
          },
          {
            "accuracy": 0.645416,
            "f1": 0.64311,
            "f1_weighted": 0.641458,
            "ap": 0.567103,
            "ap_weighted": 0.567103
          },
          {
            "accuracy": 0.652271,
            "f1": 0.652059,
            "f1_weighted": 0.651564,
            "ap": 0.572017,
            "ap_weighted": 0.572017
          },
          {
            "accuracy": 0.653042,
            "f1": 0.651698,
            "f1_weighted": 0.652944,
            "ap": 0.572734,
            "ap_weighted": 0.572734
          },
          {
            "accuracy": 0.595801,
            "f1": 0.595785,
            "f1_weighted": 0.595931,
            "ap": 0.52933,
            "ap_weighted": 0.52933
          },
          {
            "accuracy": 0.602485,
            "f1": 0.592135,
            "f1_weighted": 0.595876,
            "ap": 0.531644,
            "ap_weighted": 0.531644
          }
        ],
        "main_score": 0.641877,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.478665828704834,
  "kg_co2_emissions": null
}