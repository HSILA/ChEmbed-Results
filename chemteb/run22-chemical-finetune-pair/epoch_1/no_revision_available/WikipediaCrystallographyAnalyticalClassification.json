{
  "dataset_revision": "740565a6a853aaed1114a13bdfd5fd46857b4f11",
  "task_name": "WikipediaCrystallographyAnalyticalClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.939863,
        "f1": 0.939312,
        "f1_weighted": 0.939926,
        "ap": 0.936602,
        "ap_weighted": 0.936602,
        "scores_per_experiment": [
          {
            "accuracy": 0.938144,
            "f1": 0.936488,
            "f1_weighted": 0.937721,
            "ap": 0.907768,
            "ap_weighted": 0.907768
          },
          {
            "accuracy": 0.962199,
            "f1": 0.961846,
            "f1_weighted": 0.962288,
            "ap": 0.9636,
            "ap_weighted": 0.9636
          },
          {
            "accuracy": 0.95189,
            "f1": 0.950916,
            "f1_weighted": 0.951747,
            "ap": 0.931486,
            "ap_weighted": 0.931486
          },
          {
            "accuracy": 0.941581,
            "f1": 0.941111,
            "f1_weighted": 0.941743,
            "ap": 0.941016,
            "ap_weighted": 0.941016
          },
          {
            "accuracy": 0.958763,
            "f1": 0.957928,
            "f1_weighted": 0.958641,
            "ap": 0.93963,
            "ap_weighted": 0.93963
          },
          {
            "accuracy": 0.910653,
            "f1": 0.910525,
            "f1_weighted": 0.910932,
            "ap": 0.926446,
            "ap_weighted": 0.926446
          },
          {
            "accuracy": 0.910653,
            "f1": 0.910347,
            "f1_weighted": 0.910977,
            "ap": 0.916769,
            "ap_weighted": 0.916769
          },
          {
            "accuracy": 0.931271,
            "f1": 0.930839,
            "f1_weighted": 0.931497,
            "ap": 0.932933,
            "ap_weighted": 0.932933
          },
          {
            "accuracy": 0.982818,
            "f1": 0.982551,
            "f1_weighted": 0.98281,
            "ap": 0.976535,
            "ap_weighted": 0.976535
          },
          {
            "accuracy": 0.910653,
            "f1": 0.910567,
            "f1_weighted": 0.9109,
            "ap": 0.929838,
            "ap_weighted": 0.929838
          }
        ],
        "main_score": 0.939863,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.861006259918213,
  "kg_co2_emissions": null
}