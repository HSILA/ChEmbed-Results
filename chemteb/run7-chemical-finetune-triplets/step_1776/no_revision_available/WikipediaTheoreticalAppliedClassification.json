{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.647584,
        "f1": 0.642629,
        "f1_weighted": 0.643713,
        "ap": 0.569281,
        "ap_weighted": 0.569281,
        "scores_per_experiment": [
          {
            "accuracy": 0.694259,
            "f1": 0.694258,
            "f1_weighted": 0.694231,
            "ap": 0.607645,
            "ap_weighted": 0.607645
          },
          {
            "accuracy": 0.626564,
            "f1": 0.625978,
            "f1_weighted": 0.625125,
            "ap": 0.552356,
            "ap_weighted": 0.552356
          },
          {
            "accuracy": 0.708226,
            "f1": 0.706907,
            "f1_weighted": 0.708039,
            "ap": 0.622993,
            "ap_weighted": 0.622993
          },
          {
            "accuracy": 0.597172,
            "f1": 0.563506,
            "f1_weighted": 0.570486,
            "ap": 0.527128,
            "ap_weighted": 0.527128
          },
          {
            "accuracy": 0.630506,
            "f1": 0.630429,
            "f1_weighted": 0.630123,
            "ap": 0.55498,
            "ap_weighted": 0.55498
          },
          {
            "accuracy": 0.640703,
            "f1": 0.639957,
            "f1_weighted": 0.640901,
            "ap": 0.562515,
            "ap_weighted": 0.562515
          },
          {
            "accuracy": 0.657326,
            "f1": 0.657253,
            "f1_weighted": 0.657542,
            "ap": 0.576085,
            "ap_weighted": 0.576085
          },
          {
            "accuracy": 0.637361,
            "f1": 0.636253,
            "f1_weighted": 0.637409,
            "ap": 0.5598,
            "ap_weighted": 0.5598
          },
          {
            "accuracy": 0.637961,
            "f1": 0.635245,
            "f1_weighted": 0.633432,
            "ap": 0.561534,
            "ap_weighted": 0.561534
          },
          {
            "accuracy": 0.645758,
            "f1": 0.636505,
            "f1_weighted": 0.639844,
            "ap": 0.567777,
            "ap_weighted": 0.567777
          }
        ],
        "main_score": 0.647584,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.99578285217285,
  "kg_co2_emissions": null
}