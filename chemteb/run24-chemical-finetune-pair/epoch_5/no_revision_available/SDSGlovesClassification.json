{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.6824,
        "f1": 0.410413,
        "f1_weighted": 0.803279,
        "ap": 0.996979,
        "ap_weighted": 0.996979,
        "scores_per_experiment": [
          {
            "accuracy": 0.7895,
            "f1": 0.448112,
            "f1_weighted": 0.878699,
            "ap": 0.996663,
            "ap_weighted": 0.996663
          },
          {
            "accuracy": 0.7685,
            "f1": 0.440834,
            "f1_weighted": 0.865451,
            "ap": 0.996578,
            "ap_weighted": 0.996578
          },
          {
            "accuracy": 0.67,
            "f1": 0.406948,
            "f1_weighted": 0.798761,
            "ap": 0.996681,
            "ap_weighted": 0.996681
          },
          {
            "accuracy": 0.685,
            "f1": 0.412575,
            "f1_weighted": 0.809411,
            "ap": 0.996741,
            "ap_weighted": 0.996741
          },
          {
            "accuracy": 0.7765,
            "f1": 0.445745,
            "f1_weighted": 0.870482,
            "ap": 0.997108,
            "ap_weighted": 0.997108
          },
          {
            "accuracy": 0.734,
            "f1": 0.430529,
            "f1_weighted": 0.842917,
            "ap": 0.996937,
            "ap_weighted": 0.996937
          },
          {
            "accuracy": 0.6555,
            "f1": 0.405468,
            "f1_weighted": 0.787938,
            "ap": 0.998117,
            "ap_weighted": 0.998117
          },
          {
            "accuracy": 0.4885,
            "f1": 0.333284,
            "f1_weighted": 0.652401,
            "ap": 0.996948,
            "ap_weighted": 0.996948
          },
          {
            "accuracy": 0.529,
            "f1": 0.350725,
            "f1_weighted": 0.688223,
            "ap": 0.996613,
            "ap_weighted": 0.996613
          },
          {
            "accuracy": 0.7275,
            "f1": 0.429909,
            "f1_weighted": 0.838505,
            "ap": 0.997409,
            "ap_weighted": 0.997409
          }
        ],
        "main_score": 0.6824,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.499823808670044,
  "kg_co2_emissions": null
}