{
  "dataset_revision": "7d8df44e588b6143d4856c781f72f919fa0599a7",
  "task_name": "WikipediaSolidStateColloidalClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.772297,
        "f1": 0.769291,
        "f1_weighted": 0.770702,
        "ap": 0.752429,
        "ap_weighted": 0.752429,
        "scores_per_experiment": [
          {
            "accuracy": 0.788288,
            "f1": 0.786377,
            "f1_weighted": 0.78847,
            "ap": 0.760983,
            "ap_weighted": 0.760983
          },
          {
            "accuracy": 0.626126,
            "f1": 0.624411,
            "f1_weighted": 0.621782,
            "ap": 0.643879,
            "ap_weighted": 0.643879
          },
          {
            "accuracy": 0.777027,
            "f1": 0.776999,
            "f1_weighted": 0.777259,
            "ap": 0.770403,
            "ap_weighted": 0.770403
          },
          {
            "accuracy": 0.822072,
            "f1": 0.816255,
            "f1_weighted": 0.819642,
            "ap": 0.775396,
            "ap_weighted": 0.775396
          },
          {
            "accuracy": 0.752252,
            "f1": 0.752232,
            "f1_weighted": 0.752001,
            "ap": 0.750039,
            "ap_weighted": 0.750039
          },
          {
            "accuracy": 0.786036,
            "f1": 0.777079,
            "f1_weighted": 0.781708,
            "ap": 0.738278,
            "ap_weighted": 0.738278
          },
          {
            "accuracy": 0.806306,
            "f1": 0.80046,
            "f1_weighted": 0.803999,
            "ap": 0.761972,
            "ap_weighted": 0.761972
          },
          {
            "accuracy": 0.84009,
            "f1": 0.83966,
            "f1_weighted": 0.84052,
            "ap": 0.82665,
            "ap_weighted": 0.82665
          },
          {
            "accuracy": 0.75,
            "f1": 0.749439,
            "f1_weighted": 0.748212,
            "ap": 0.758488,
            "ap_weighted": 0.758488
          },
          {
            "accuracy": 0.774775,
            "f1": 0.769996,
            "f1_weighted": 0.773431,
            "ap": 0.738203,
            "ap_weighted": 0.738203
          }
        ],
        "main_score": 0.772297,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.078183650970459,
  "kg_co2_emissions": null
}