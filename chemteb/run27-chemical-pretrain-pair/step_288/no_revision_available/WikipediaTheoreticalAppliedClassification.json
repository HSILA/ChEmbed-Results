{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.36.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.616787,
        "f1": 0.613074,
        "f1_weighted": 0.614199,
        "ap": 0.544452,
        "ap_weighted": 0.544452,
        "scores_per_experiment": [
          {
            "accuracy": 0.626821,
            "f1": 0.626701,
            "f1_weighted": 0.626316,
            "ap": 0.552241,
            "ap_weighted": 0.552241
          },
          {
            "accuracy": 0.602742,
            "f1": 0.602588,
            "f1_weighted": 0.603039,
            "ap": 0.533954,
            "ap_weighted": 0.533954
          },
          {
            "accuracy": 0.664439,
            "f1": 0.663149,
            "f1_weighted": 0.664349,
            "ap": 0.582492,
            "ap_weighted": 0.582492
          },
          {
            "accuracy": 0.615596,
            "f1": 0.61035,
            "f1_weighted": 0.612954,
            "ap": 0.542209,
            "ap_weighted": 0.542209
          },
          {
            "accuracy": 0.61611,
            "f1": 0.611993,
            "f1_weighted": 0.614295,
            "ap": 0.542711,
            "ap_weighted": 0.542711
          },
          {
            "accuracy": 0.603085,
            "f1": 0.601182,
            "f1_weighted": 0.599596,
            "ap": 0.536057,
            "ap_weighted": 0.536057
          },
          {
            "accuracy": 0.632819,
            "f1": 0.632712,
            "f1_weighted": 0.633073,
            "ap": 0.556432,
            "ap_weighted": 0.556432
          },
          {
            "accuracy": 0.617995,
            "f1": 0.616034,
            "f1_weighted": 0.617614,
            "ap": 0.544463,
            "ap_weighted": 0.544463
          },
          {
            "accuracy": 0.591774,
            "f1": 0.591289,
            "f1_weighted": 0.590478,
            "ap": 0.527492,
            "ap_weighted": 0.527492
          },
          {
            "accuracy": 0.596487,
            "f1": 0.57474,
            "f1_weighted": 0.580278,
            "ap": 0.526472,
            "ap_weighted": 0.526472
          }
        ],
        "main_score": 0.616787,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.964967012405396,
  "kg_co2_emissions": null
}