{
  "dataset_revision": "c723236c5ec417d79512e6104aca9d2cd88168f6",
  "task_name": "SDSGlovesClassification",
  "mteb_version": "1.36.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.60475,
        "f1": 0.376421,
        "f1_weighted": 0.736234,
        "ap": 0.996917,
        "ap_weighted": 0.996917,
        "scores_per_experiment": [
          {
            "accuracy": 0.7425,
            "f1": 0.43359,
            "f1_weighted": 0.848537,
            "ap": 0.996971,
            "ap_weighted": 0.996971
          },
          {
            "accuracy": 0.7465,
            "f1": 0.433149,
            "f1_weighted": 0.851231,
            "ap": 0.99649,
            "ap_weighted": 0.99649
          },
          {
            "accuracy": 0.4295,
            "f1": 0.304817,
            "f1_weighted": 0.596872,
            "ap": 0.996711,
            "ap_weighted": 0.996711
          },
          {
            "accuracy": 0.665,
            "f1": 0.406449,
            "f1_weighted": 0.795059,
            "ap": 0.997158,
            "ap_weighted": 0.997158
          },
          {
            "accuracy": 0.8075,
            "f1": 0.45926,
            "f1_weighted": 0.889732,
            "ap": 0.99773,
            "ap_weighted": 0.99773
          },
          {
            "accuracy": 0.713,
            "f1": 0.422906,
            "f1_weighted": 0.828792,
            "ap": 0.996853,
            "ap_weighted": 0.996853
          },
          {
            "accuracy": 0.611,
            "f1": 0.386411,
            "f1_weighted": 0.754663,
            "ap": 0.997439,
            "ap_weighted": 0.997439
          },
          {
            "accuracy": 0.319,
            "f1": 0.245037,
            "f1_weighted": 0.47945,
            "ap": 0.996268,
            "ap_weighted": 0.996268
          },
          {
            "accuracy": 0.379,
            "f1": 0.279261,
            "f1_weighted": 0.545231,
            "ap": 0.997007,
            "ap_weighted": 0.997007
          },
          {
            "accuracy": 0.6345,
            "f1": 0.393331,
            "f1_weighted": 0.772776,
            "ap": 0.996538,
            "ap_weighted": 0.996538
          }
        ],
        "main_score": 0.60475,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.094484090805054,
  "kg_co2_emissions": null
}